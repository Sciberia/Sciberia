Машинное обучение, лекция 4 (Jaakkola) 

$\textbf{Метод опорных векторов и регуляризация}$

Мы предложили простую ослабленную оптимизационную задачу для нахождения разделяющей границы с максимальным отступом, в которой некоторые объекты могут классифицироваться неверно.

$\text{минимизировать } \frac{1}{2}\left \| \theta \right \|^{2}+\textit{C}\sum_{t=1}^{n}\xi_{t} \textbf{  (1)}$

$\text{при условии } y_t(\theta^{T}\textbf{x}_{t}+\theta_{0})\geq 1-\xi_{t}\text{ и }\xi_{t}\geq 0\text{ для всех } t=1,...,n\text{   (2)}$

где параметр $\textit{C}$ может быть подобран с помощью перекрестной проверки, минимизируя ошибку на leave-one-out cross-validation.

Наша цель сейчас вкратце понять ослабление оптимизационной задачи с точки зрения $\textit{регуляризации }$ (regularization)

Регуляризация обычно формулируется как оптимизационная задача, в которой фигурирует желаемая целевая функция (потери на классификации в нашем случае) и регуляризатор (regularization penalty). 

Регуляризатор используется, чтобы помочь стабилизировать минимизацию целевой функции или внедрить априорные знания, которые мы могли бы иметь о желаемом  решении.

Таким образом многие методы машинного обучения могут быть рассмотрены как методы регуляризации.

Для дальнейшего удобства мы будем рассматривать SVM задачу оптимизации, как задачу регуляризации.

Рисунок 1.

Рисунок 1: a) Т.н. "hinge loss" $(1-z)^{+}$ как функция от $\textit{z}$. b) логистические потери (logistic loss) log[1+exp(-z)] как функция от $\textit{z}$.

Возвращаясь к ослабленной оптимизационной задаче в рамках задачи регуляризации, определим функцию потерь, которая соответствует индивидуально оптимизируемым значениям $\xi_{t}$ - штрафы за нарушениее каждого из ограничений отступа.

Мы фактически решаем оптимизационную задачу относительно значений $\xi$ для фиксированых $\theta$ и $\theta_0$

Это ведет к представлению $C\Sigma_{t}\xi_{t}$ как функции от $\theta$ и $\theta_0$.

Необходимая нам функция потерь основывается на $\textit{hinge loss}$ потерях $h(z)$, определеных как положительная часть (положительная срезка) $1-z$, которая записывается как $(1-z)^{+}$ (смотрите рисунок 1а).

Ослабленая оптимизационная задача может быть записана с использованием hinge loss как

$$\text{минимизировать}\frac{1}{2}\left \| \theta \right\|^{2}+C\sum_{t=1}^{n}\overset{=\hat{\xi}_{t}}{ \overbrace{(1-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))^{+}}}$$

Здесь $\left \| \theta \right \|^{2}/2$ квадрат обратного геометрического отступа представляется в виде регуляризатора, который помогает стабилизировать целевую функцию

$$C\sum_{t=1}^{n}{(1-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))^{+}}$$

Другими словами, когда ни одно ограничение отступа не нарушается (потери равны 0), регуляризатор помогает нам выбрать решение с наибольшим геометрическим отступом.

$\textbf{Логистическая регрессия, метод максимума правдоподобия}$

Рисунок 2

Рисунок 2: Логистическая функция $g(z) = (1 + exp(-z))^{-1}$

Другой способ учесть возможность шумной разметки в линейном классификаторе заключается в том, чтобы смоделировать ее возникновение.

Например, человек, назначающий метки, как правило очень хорошо справляется с "рядовыми примерами", но сомневается в более сложных случаях.

Простая модель учета шумной разметки при использовании линейного классификатора - это логистическая регрессия.

В этой модели мы задаем вероятностное распределение на двух метках, в таком случае метки примеров, которые далеки от разделяющей границы, с большей вероятностью будут правильными.

Более точно можно записать как

$$P(y = 1|\textbf{x}, \theta, \theta_{0}) = g(\theta^{T}\textbf{x} + \theta_{0}) (5)$$

где $g(z) = (1 + exp(-z))^{-1}$ называется логистической функцией (Рисунок 2).

Один из способов задать вид логистической функции состоит в том, чтобы потребовать, чтобы логарифм отношения предсказанных вероятностей классов был бы линейной функцией:

$\text{log}\frac{P(y = 1|\textbf{x}, \theta, \theta_{0})}{P(y = -1|\textbf{x}, \theta, \theta_{0}) } =\theta^{T}\textbf{x}+\theta_{0}\text{  (6)}$

Заметим, что когда мы предсказываем одинаковую вероятность (1/2) для обеих классов, логарифм отношения вероятностей равен нулю и мы получаем разделяющую границу $\theta^{T}\textbf{x} + \theta_{0}= 0$.

Точная запись логистической функции или, что эквивалентно, требование к логарифму отношения вероятностей быть линейной функцией, может казаться слегка произвольной (но, возможно, не настолько, как hinge loss, используемые в SVM).

Позже в курсе мы определим вид логистической функции, основываясь на определенных предположения касательно условных распределений вероятностей $P(x|y=1)$ и $P(x|y=-1)$.

В целях сравнения модели логистической регрессии и SVM запишем условную вероятность $P(y|x, \theta, \theta_0)$ немного более лаконично.

Имея в виду, что $1-g(z) = g(-z)$, получим

$P(y=-1|x, \theta, \theta_0) = 1 - P(y|x, \theta, \theta_0) = 1-g(\theta^Tx+\theta_0) = g(-(\theta^Tx+\theta_0)) (7)$

и потому

$P(y|x, \theta, \theta_0) = g(y(\theta^Tx+\theta_0)) (8)$

Итак, теперь мы имеем линейный классификатор, который делает вероятностные предсказания о метках.

Как нам следует обучать такую модель?

Разумным критерием представляется максимизация вероятности, что мы предсказываем верные метки для каждого примера.

В предположении, что каждый объект размечен независимо от других, вероятность назначить правильные метки объектам задается произведением

$L(\theta ,\theta _{0})=\prod_{t=1}^{n}P(y_{t}|\textbf{x}_{t},\theta,\theta_{0}) (9)$

$L(\theta ,\theta _{0})$ называется функционалом правдоподобия и интерпретируется как функция от параметров $\theta $ и $\theta _{0}$ при фиксированных данных (метки и объекты).

Максимизируя это функционал правдоподобия относительно $\theta $ и $\theta _{0}$ мы получаем оценки максимального правдоподобия параметров.

Статистические оценки максимального правдоподобия имеют ряд замечательных свойств.

Статистическая оценка - это функция сопоставляющая данным значения параметров. Оценка, в данном случае, - это полученное значение параметров для определенных данных.

Например, предположим, мы знаем истинную модель$^{1}$ класса (модель логистической регрессии) и зафиксированы определенные условия, тогда статистические оценки максималбного правдоподобия будут a) достоверными (мы получим правильные значения параметров при условии достаточного количества примеров), и b) еффективными (ни одна другая статистическая оценка не сойдется к вернрым значением параметров быстрее в терминах среднеквадратической  ошибки).

$^{1}$Прим. пер.: Термин «модель» здесь подразумевается точно в таком же смысле, как и в первой лекции – параметризованное множество функций. Собственно эти параметры и надо найти с помощью статистических оценок максимального правдоподобия.

Но что если мы не знаем истинной модели класса.

Neither property may hold as a result.

Более робастные/устойчивые (robust) статистические оценки могут быть найдены в широком классе, называемом М-оценки (M-estimators), который включает метод максимума правдоподобия.

Тем не менее мы будем использовать принцип максимального правдоподобия для нахождения значений параметров.

Произведение в функционале правдоподобия несколько проблематично для непосредственной работы, поэтому будем максимизировать его логарифм:

$l(\theta,\theta _{0})=\sum_{t=1}^{n}\text{log}P(y_{t}| \textbf{x}_{t},\theta, \theta_{0} ) \text{    (10)}$

Как вариант, мы можем минимизировать отрицательный логарифм

$$\begin{align}-l(\theta,\theta_{0}) &= \sum_{t=1}^{n}\overset{\text{log-loss}}{\overbrace{-\text{log }P(y_{t}|\textbf{x}_{t},\theta,\theta_{0})}}&\text{  (11)}\\ &= \sum_{t=1}^{n}-\text{log }g(y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0})) &\text{  (12)}\\ &= \sum_{t=1}^{n}-\text{log}[1+\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))]&\text{  (13)}\end{align}$$

Можно интерпретировать это в точности также, как сумму hinge loss в алгоритме SVM.

Как и раньше мы имеем базовую функцию потерь, в нашем случае log[1+exp(-z)] (Рисунок 1b) похожую на hinge loss и зависящую только от значения отступа $y_t(\theta^Tx_t+\theta_0)$ на каждом объекте.

Отличие здесь заключается в том, что мы имеем ясную вероятностную интерпретацию "силы" предсказания$^{2}$, т.е. насколько велико значение $P(y_t|x_t,\theta, \theta_0)$ для какого-либо отдельного примера.

$^{2}$Прим.пер.:  Данная величина также называется "степенью уверенности классификатора в своем предсказании".

Наличие подобной интерпретации вовсе не означает, что значения вероятностей всегда разумны или точны (calibrated).

Предсказываемые вероятности считаются точными, когда соответствую наблюдаемым частотам.

Так, например, если мы соберем вместе все примеры, которым предсказана вероятность принадлежать положительному классу 0,5, приблизительно половина из них должна быть размечена как +1.

Оценки вероятности редко являются точными, но тем не менее могут быть полезными.

Задача минимизации, которую мы определили выше, выпуклая и существует ряд оптимизационных методов для нахождения оптимальных параметров $\hat{\theta}$ и $\hat{\theta}_0$, включая простой градиентный спуск.

В простом (стохастическом) градиентном спуске мы изменяем параметры относительно каждого слагаемого в сумме (основанном на каждом обучающем примере).

Чтобы записать обновления параметров, нам необходимы следующие производные

$$\begin{align}\frac{d}{d\theta_{0}}\text{log}[1+\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))] &= -y_{t}\frac{\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))}{1+\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))}&\text{  (14)}\\ &= -y_{t}[1-P(y_{t}|(\textbf{x}_{t},\theta,\theta_{0})] &\text{  (15)}\end{align}$$

и

$$\frac{d}{d\theta}\text{log}[1+\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))]=-y_{t}\textbf{x}_{t}[1-P(y_{t}|(\textbf{x}_{t},\theta,\theta_{0})] \text{  (16)}$$

Параметры обновляются путем случайного выбора примера и смещения параметров в сторону противоположную направлению градиента:

$\theta_{0}\leftarrow\theta_{0} + \eta\cdot y_{t}[1 - P(y_{t}|\textbf{x}_{t}, \theta, \theta_{0})] (17)$

$\theta\leftarrow\theta + \eta\cdot y_{t}\textbf{x}_{t}[1 - P(y_{t}|\textbf{x}_{t}, \theta, \theta_{0})] (18)$

Где $\eta$ - малая положительная величина, скорость спуска/обучения (learning rate).

Заметим, что $P(y_{t}|\textbf{x}_{t}, \theta, \theta_{0})$ - вероятность верно предсказать метку, а $1-P(y_{t}|\textbf{x}_{t}, \theta, \theta_{0})$ - вероятность сделать ошибку.

Видно, что обновления параметров при градиентном спуске в контексте логистической регрессии очень напоминают правила обновления алгоритма персептрон основанные на допущенных ошибках.

Основное отличие здесь в том, что обновления пропорциональны вероятности сделать ошибку.

The stochastic gradient descent algorithm leads to no significant change on average when the gradient of the full objective equals zero.

Равентство градиента нулю является необходимым условием оптимальности.

$\frac{d}{d\theta_{0}}(-l(\theta,\theta _{0}))=-\sum_{t=1}^{n}y_{t}[1-P(y_{t}| \textbf{x}_{t},\theta, \theta_{0} )]=0 \text{    (19)}$

$\frac{d}{d\theta}(-l(\theta,\theta _{0}))=-\sum_{t=1}^{n}y_{t} \textbf{x}_{t}[1-P(y_{t}| \textbf{x}_{t},\theta, \theta_{0} )]=0 \text{    (20)}$

Сумма в уравнении (19) показывает различие между вероятностями совершить ошибку для положительных и отрицательных примеров.

Поэтому, оптимальное значение $\theta_0$ обеспечивает баланс между ошибками в терминах вероятностей.

Из этого также следует, что вектор вероятностей ошибок ортогонален вектору меток.

Похожим образом оптимальное значение $\theta$ характеризуется вероятностями ошибок, которые ортогональны матрице объект-метка $\widetilde{X}= [y_{1}\textbf{x}_{1}, ..., y_{n}\textbf{x}_{n}]$.

Другими словами, для каждой компоненты $j$ векторов объектов вектор $[y_{1}\textbf{x}_{1j},..., y_{n}\textbf{x}_{nj}]$  ортогонален вероятностям ошибки.

Взятые совместно, эти условия ортогональности гарантируют, что никакие другие линейные операции над данными не позволят улучшить предсказываемые вероятности (или вероятности ошибок).

Возможно, увидеть этот факт можно будет проще если мы сначала переведем метки $\pm1$ в метки 0/1: $\widetilde{y}_{t}=(1 + y_{t})/2$, так что $\widetilde{y}_{t}\in\{0,1\}$.

Тогда оба условия оптимальности могут быть переписаны в терминах ошибок предскмазания вместо вероятностей ошибок как

$\sum_{t=1}^{n}[\widetilde{y_{t}}-P(y=1|\textbf{x}_{t},\theta,\theta_{0})]=0\text{   (21)}$

$\sum_{t=1}^{n}\textbf{x}_{t}[\widetilde{y_{t}}-P(y=1|\textbf{x}_{t},\theta,\theta_{0})]=0\text{   (22)}$

и

${\theta}'_{0}\sum_{t=1}^{n}[\widetilde{y_{t}}-P(y=1|\textbf{x}_{t},\theta,\theta_{0})]+{\theta}'^{T}\sum_{t=1}^{n}\textbf{x}_{t}[\widetilde{y_{t}}-P(y=1|\textbf{x}_{t},\theta,\theta_{0})]=0\text{   (23)}$

$\sum_{t=1}^{n}({\theta}'^{T}\textbf{x}_{t}+{\theta}'_{0})[\widetilde{y_{t}}-P(y=1|\textbf{x}_{t},\theta,\theta_{0})]=0\text{   (24)}$

означает, что вектор ошибо предсказания ортогонален любой линейной функции от данных.

Давайте попробуем коротко понять вид предсказаний, которые мы могли бы получить с помощью метода максимального правдоподобия на модели логистической регрессии.

Предположим обучающая выборка линейно разделима.

В этом случае мы можем найти такие значения параметров, чтобы величина $y_{t}(\theta^{T}\textbf{x}_{t} + \theta_{0})$ положительна для всех примеров из обучающей выборки. 

Пропорциональное увеличение параметров позволит нам делать значение отступа все больше и больше. 

Это выгодно с точки зрения максимума правдоподобия, т.к. логорифм логистической функции строго возрастающая функция от $y_{t}(\theta^{T}\textbf{x}_{t} + \theta_{0})$ (функция потерь $log[1 + exp (-y_{t}(\theta^{T}\textbf{x}_{t} + \theta_{0}))]$ строго убывающая).

Таким образом, значения параметров при использовании метода максимального правдоподобия будут неограниченно возрастать, и бесконечное пропорциональное увеличение параметров, соответствующих любому линейному классификатору, идеально разделяющему обучающую выборку, будет способствовать получению наибольшего правдоподобия (в точности еденица для функционала правдоподобия или в точности ноль для функции потерь).

Конечные значения вероятностей, классифицирующие каждый объект из обучающей выборки с вероятностью единица, через чур точные, чтобы отразить нашу неуверенность о том, какие метки могут быть.

В случае, когда обучающая выборка мала, нам необходимо добавить регуляризатор $\left \| \theta \right \|^{2}/2$ в точности как в алгоритме SVM.

Регуляризатор помогает выбрать разумные параметры, когда даоступная обучающая выборка не способна в достаточной мере определить линейный классификатор.

Для оценки параметров модели логистической регрессии с регуляризации мы будем минимизировать

$\frac{1}{2}\left \| \theta \right \|^{2}+C\sum_{t=1}^{n}\text{log}[1+\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))] \text{  (25)}$

где конгстанта $C$ снова задает компромис между верной классификацией и регуляризационным штрафом.

Регуляризованная задача обычно записывается как

$\frac{\lambda}{2}\left \| \theta \right \|^{2}+\sum_{t=1}^{n}\text{log}[1+\text{exp}(-y_{t}(\theta^{T}\textbf{x}_{t}+\theta_{0}))] \text{  (26)}$

так как кажется более естественным изменять силу регуляризации с помощью параметр $\lambda$, оставляя функцию потерь без изменения.

Внимание! Этот перевод, возможно, ещё не готов.
Его статус: идёт перевод

Переведено на Нотабеноиде
http://translate.kursomir.ru/book/105/805

Переводчики: chargered

