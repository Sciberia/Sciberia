1
00:00:00,000 --> 00:00:00,080


2
00:00:00,080 --> 00:00:01,770
Материалы этой
лекции предоставлены

3
00:00:01,770 --> 00:00:04,010
под лицензией
Creative Commons.

4
00:00:04,010 --> 00:00:06,860
Ваша поддержка помогает
платформе МИТ OpenCourseWare

5
00:00:06,860 --> 00:00:10,720
предоставлять высококачественные
образовательные материалы бесплатно.

6
00:00:10,720 --> 00:00:13,330
Поддержать нас материально и
ознакомиться с остальными

7
00:00:13,330 --> 00:00:17,228
курсами МИТ, вы можете, посетив
веб-сайт МИТ OpenCourseWare,

8
00:00:17,228 --> 00:00:17,853
расположенный по адресу ocw.mit.edu

9
00:00:17,853 --> 00:00:23,290


10
00:00:23,290 --> 00:00:27,010
ПРОФЕССОР: Итак, сегодняшняя
лекция о сортировках.

11
00:00:27,010 --> 00:00:31,310
Сегодня мы будем говорить о
конкретных алгоритмах сортировки.

12
00:00:31,310 --> 00:00:34,570
Я хочу начать с мотивации,
для понимания того, почему

13
00:00:34,570 --> 00:00:37,105
нам интересны сортировки. Это
должно быть достаточно просто.

14
00:00:37,105 --> 00:00:39,690


15
00:00:39,690 --> 00:00:42,490
Затем я хочу обсудить конкретный
алгоритм сортировки,

16
00:00:42,490 --> 00:00:45,470
который называется
сортировка вставками.

17
00:00:45,470 --> 00:00:47,860
Это, вероятно, самый
простой алгоритм сортировки,

18
00:00:47,860 --> 00:00:51,942
который вы можете написать.
Он занимает пять строчек кода.

19
00:00:51,942 --> 00:00:53,400
Это не самый лучший
алгоритм сортировки

20
00:00:53,400 --> 00:00:57,430
из всех и поэтому мы
попытаемся улучшить его.

21
00:00:57,430 --> 00:01:00,470
Также мы поговорим об алгоритме
сортировки слиянием, основанном

22
00:01:00,470 --> 00:01:03,250
на парадигме "разделяй и властвуй".
Это должно дать мотивацию для

23
00:01:03,250 --> 00:01:09,010
последнего пункта, на который
я хочу потратить время, -

24
00:01:09,010 --> 00:01:12,300
рекуррентные соотношения
и то, как их решать.

25
00:01:12,300 --> 00:01:14,230
Чаще всего, рекуррентные
соотношения, которые мы

26
00:01:14,230 --> 00:01:18,120
будем рассматривать в нашем
курсе, будут появляться из задач

27
00:01:18,120 --> 00:01:20,760
на принцип "разделяй и властвуй".
Например, сортировка слиянием.

28
00:01:20,760 --> 00:01:24,300
Вы будете встречать такие
соотношения снова и снова.

29
00:01:24,300 --> 00:01:26,965
Итак, давайте поговорим о том,
почему нам интересна сортировка.

30
00:01:26,965 --> 00:01:30,110


31
00:01:30,110 --> 00:01:34,370
Существует несколько довольно
очевидных ее применений.

32
00:01:34,370 --> 00:01:37,490
Например, если вы хотите
иметь телефонную книгу.

33
00:01:37,490 --> 00:01:42,010
У вас есть набор имен и номеров,
соответствующих телефонному

34
00:01:42,010 --> 00:01:44,830
справочнику. И вы хотите
хранить их в отсортированном

35
00:01:44,830 --> 00:01:46,330
порядке, чтобы можно было 
легко найти нужный номер.

36
00:01:46,330 --> 00:01:51,510
Еще как пример музыкальные библиотеки,
электронные таблицы и так далее.

37
00:01:51,510 --> 00:01:54,590
Так что есть много
очевидных применений.

38
00:01:54,590 --> 00:01:59,630
Также есть несколько
интересных задач, которые

39
00:01:59,630 --> 00:02:05,900
становятся легкими, как только
элементы отсортированы.

40
00:02:05,900 --> 00:02:13,790


41
00:02:13,790 --> 00:02:18,170
Один из примеров такой
задачи - поиск медианы.

42
00:02:18,170 --> 00:02:23,860


43
00:02:23,860 --> 00:02:27,220
Скажем, у вас есть
набор элементов

44
00:02:27,220 --> 00:02:36,210
в массиве с индексами
от 0 до n. Массив

45
00:02:36,210 --> 00:02:38,650
содержит n чисел и эти
числа не отсортированы.

46
00:02:38,650 --> 00:02:44,850


47
00:02:44,850 --> 00:02:48,950
Когда вы сортируете массив, вы
преобразовываете его в массив B

48
00:02:48,950 --> 00:02:52,760
с индексами от 0 до n.
Если элементы массива это числа,

49
00:02:52,760 --> 00:02:55,660
вы можете отсортировать их в
возрастающем или убывающем порядке.

50
00:02:55,660 --> 00:02:58,690
Давайте пока считать, что
порядок возрастающий.

51
00:02:58,690 --> 00:03:01,650
Если же элементы массива
это структуры, а не числа,

52
00:03:01,650 --> 00:03:04,520
тогда вы должны предоставить
функцию сравнения,

53
00:03:04,520 --> 00:03:08,050
чтобы определить, какая
из структур меньше.

54
00:03:08,050 --> 00:03:09,520
И это еще один параметр,
который вы должны

55
00:03:09,520 --> 00:03:12,980
передать на вход, чтобы
произвести сортировку.

56
00:03:12,980 --> 00:03:15,310
На самом деле не важно,
чем являются элементы,

57
00:03:15,310 --> 00:03:17,580
пока у вас есть
функция сравнения.

58
00:03:17,580 --> 00:03:19,930
Думайте о ней, как о знаке
"меньше либо равно".

59
00:03:19,930 --> 00:03:23,750
Если у вас есть такая функция,
она, очевидно, простая,

60
00:03:23,750 --> 00:03:27,090
в случае, когда нужно проверить,
что 3 меньше 4 и так далее.

61
00:03:27,090 --> 00:03:29,640
Но функция может быть
чуть более сложной

62
00:03:29,640 --> 00:03:32,990
для более сложных
применений сортировки.

63
00:03:32,990 --> 00:03:36,570
Но в конечном итоге,
если у вас есть алгоритм,

64
00:03:36,570 --> 00:03:39,120
принимающий на
вход функцию сравнения,

65
00:03:39,120 --> 00:03:42,670
спустя некоторое количество
времени вы должны получить

66
00:03:42,670 --> 00:03:45,100
массив B с индексами от 0 до n.

67
00:03:45,100 --> 00:03:48,680
Теперь, если вы хотели найти
медиану среди множества чисел,

68
00:03:48,680 --> 00:03:51,720
которые изначально
были в массиве A,

69
00:03:51,720 --> 00:03:56,090
что вам нужно сделать после того, как
вы получили отсортированный массив B?

70
00:03:56,090 --> 00:03:59,124
ГОЛОС ИЗ АУДИТОРИИ: Нет более
эффективного алгоритма поиска медианы?

71
00:03:59,124 --> 00:04:00,040
ПРОФЕССОР: Точно.

72
00:04:00,040 --> 00:04:08,120
Это что-то вроде побочного
эффекта у отсортированного списка.

73
00:04:08,120 --> 00:04:10,240
Если вам посчастливилось иметь
отсортированный список,

74
00:04:10,240 --> 00:04:15,090
существует много способов,
которые вы можете представить,

75
00:04:15,090 --> 00:04:16,310
для построения
отсортированного списка.

76
00:04:16,310 --> 00:04:19,779
Один способ - у вас есть что-то
полностью неупорядоченное

77
00:04:19,779 --> 00:04:22,620
и вы запускаете сортировку
вставками или сортировку слиянием.

78
00:04:22,620 --> 00:04:25,140
Другой способ - поддерживать
отсортированный список, в тот момент,

79
00:04:25,140 --> 00:04:27,660
когда вы помещаете элементы в него.

80
00:04:27,660 --> 00:04:29,640
Так что, если вам посчастливилось
иметь упорядоченный список

81
00:04:29,640 --> 00:04:32,600
и он вам нужен
по какой-то причине,

82
00:04:32,600 --> 00:04:35,440
я хочу сказать, то, что
найти медиану

83
00:04:35,440 --> 00:04:37,140
легко.

84
00:04:37,140 --> 00:04:39,430
И это легко, потому что
все, что вам нужно - это

85
00:04:39,430 --> 00:04:43,805
посмотреть - в зависимости
от того, четное n

86
00:04:43,805 --> 00:04:47,527
или нечетное - посмотреть
на элемент B[n/2].

87
00:04:47,527 --> 00:04:49,360
И это дало бы вам
медиану, потому что

88
00:04:49,360 --> 00:04:54,210
у вас будет набор чисел,
которые меньше этого

89
00:04:54,210 --> 00:04:56,830
и такой же набор чисел,
которые больше этого.

90
00:04:56,830 --> 00:04:59,770
А это и является
определением медианы.

91
00:04:59,770 --> 00:05:05,030
Итак, это не обязательно лучший
способ, как вы упомянули ранее,

92
00:05:05,030 --> 00:05:06,400
для поиска медианы.

93
00:05:06,400 --> 00:05:11,320
Но он работает за константное время,
если у вас есть отсортированный список.

94
00:05:11,320 --> 00:05:14,650
Это то, на что я хотел
обратить внимание.

95
00:05:14,650 --> 00:05:16,720
Есть и другие вещи, которые
вы могли бы проделать.

96
00:05:16,720 --> 00:05:20,780
О них вы узнаете
в лекции Эрика.

97
00:05:20,780 --> 00:05:25,570
Например, понятие
бинарного поиска - поиск

98
00:05:25,570 --> 00:05:28,650
элемента в массиве,
определенного элемента.

99
00:05:28,650 --> 00:05:34,090
У вас есть список
элементов - снова от 0 до n.

100
00:05:34,090 --> 00:05:39,600
И вы ищете определенное
число или элемент.

101
00:05:39,600 --> 00:05:43,550


102
00:05:43,550 --> 00:05:46,640
Вы могли бы, очевидно,
просмотреть массив

103
00:05:46,640 --> 00:05:50,260
и поиск этого элемента
занял бы линейное время.

104
00:05:50,260 --> 00:05:53,100
Если массив уже отсортирован,

105
00:05:53,100 --> 00:05:58,530
вы можете найти элемент за
логарифмическаое время,

106
00:05:58,530 --> 00:06:00,295
используя то, что называется
бинарным поиском.

107
00:06:00,295 --> 00:06:03,600


108
00:06:03,600 --> 00:06:05,880
Скажем, вы ищете
определенный элемент.

109
00:06:05,880 --> 00:06:08,280
Назовем его k.

110
00:06:08,280 --> 00:06:11,140
Бинарный поиск, строго говоря,
делал бы следующее -

111
00:06:11,140 --> 00:06:20,200
вы сравниваете k,
опять же, с элементом B[n/2],

112
00:06:20,200 --> 00:06:23,780
и, на основании того, что
B отсортирован, решаете,

113
00:06:23,780 --> 00:06:28,400
в какой половине
массива искать дальше.

114
00:06:28,400 --> 00:06:33,080
Если B[n/2] не равен k,
тогда, - что ж,

115
00:06:33,080 --> 00:06:34,390
если он точно равен k,
вы нашли элемент.

116
00:06:34,390 --> 00:06:36,770
В противном случае вы
ищете в левой половине.

117
00:06:36,770 --> 00:06:39,670
Вы используете парадигму
"разделай и властвуй".

118
00:06:39,670 --> 00:06:42,820
И вы можете сделать это
за логарифмическое время.

119
00:06:42,820 --> 00:06:45,700
Поэтому помните об этом,
потому что бинарный поиск

120
00:06:45,700 --> 00:06:48,530
еще встретиться в
сегодняшней лекции

121
00:06:48,530 --> 00:06:50,760
и в других.

122
00:06:50,760 --> 00:06:53,750
Это действительно крутая
парадигма - разделяй и властвуй -

123
00:06:53,750 --> 00:06:56,020
возможно, самая простейшая.

124
00:06:56,020 --> 00:06:57,690
И она, по сути, берет
что-то, что занимает

125
00:06:57,690 --> 00:07:01,040
линейное время -
линейный поиск,

126
00:07:01,040 --> 00:07:03,770
и преобразовывает
его в поиск за логарифм.

127
00:07:03,770 --> 00:07:06,540
Так что вот несколько задач,
которые становятся

128
00:07:06,540 --> 00:07:10,950
легкими, если у вас есть
отсортированный список.

129
00:07:10,950 --> 00:07:21,270
И еще есть несколько не таких
очевидных применений

130
00:07:21,270 --> 00:07:25,150
сортировки. Например,
сжатие данных.

131
00:07:25,150 --> 00:07:27,790
Если вы хотите
сжать файл,

132
00:07:27,790 --> 00:07:30,530
одна из вещей которые
вы можете сделать,

133
00:07:30,530 --> 00:07:35,330
если у вас есть множество элементов, -
отсортировать эти элементы.

134
00:07:35,330 --> 00:07:37,870
И это позволит автоматически
найти повторяющиеся элементы.

135
00:07:37,870 --> 00:07:42,940
Вы можете сказать, что, если
у меня есть 100 одинаковых элементов,

136
00:07:42,940 --> 00:07:47,779
я могу сжать файл, представив
его в виде одного элемента и

137
00:07:47,779 --> 00:07:49,320
числа, которое
соответствует

138
00:07:49,320 --> 00:07:52,770
частоте этого элемента -
похоже на то, что делат

139
00:07:52,770 --> 00:07:54,440
расстояние между документами.

140
00:07:54,440 --> 00:07:57,750
Расстояние между документами
можно рассматривать как способ

141
00:07:57,750 --> 00:07:59,770
сжатие ваших начальных
входных данных.

142
00:07:59,770 --> 00:08:03,240
Очевидно, вы потеряете труды
Шекспира или чего-то еще.

143
00:08:03,240 --> 00:08:06,560
Это станет просто
набором слов и частот.

144
00:08:06,560 --> 00:08:12,870
Но этот способ позволяет
сжать входные данные

145
00:08:12,870 --> 00:08:15,590
и дает другое
представление.

146
00:08:15,590 --> 00:08:20,395
Вот так люди используют сортировку
как часть сжатия данных.

147
00:08:20,395 --> 00:08:23,190


148
00:08:23,190 --> 00:08:27,360
Компьютерная графика
использует сортировки.

149
00:08:27,360 --> 00:08:30,560
Большую часть времени,
при рендеринге

150
00:08:30,560 --> 00:08:32,870
в компьютерной графике,
у вас есть много слоев.

151
00:08:32,870 --> 00:08:34,559
Каждый соответствует своей сцене.

152
00:08:34,559 --> 00:08:38,550
Получается, что в
компьютерной графике

153
00:08:38,550 --> 00:08:40,299
большую часть времени
вы делаете рендеринг

154
00:08:40,299 --> 00:08:44,410
от задней сцены к передней, потому что
когда у вас есть большой прозрачный

155
00:08:44,410 --> 00:08:48,887
объект впереди, вы хотите
отрендерить сначала его.

156
00:08:48,887 --> 00:08:50,970
Поэтому вы не должны
беспокоиться обо всем, что

157
00:08:50,970 --> 00:08:54,060
происходит позади этого
большого прозрачного объекта.

158
00:08:54,060 --> 00:08:56,590
И это делает вещи
более эффективными.

159
00:08:56,590 --> 00:08:58,700
И таким образом вы держите вещи
отсортированными, от ближнего к дальнему,

160
00:08:58,700 --> 00:09:01,160
большую часть времени,
во время рендеринга.

161
00:09:01,160 --> 00:09:03,860
Но иногда, если вы
беспокоитесь о прозрачности,

162
00:09:03,860 --> 00:09:05,660
вы должны рендерить сцены
от задней к ближней.

163
00:09:05,660 --> 00:09:08,390
Итак, обычно у вас есть
отсортированные списки,

164
00:09:08,390 --> 00:09:11,550
соответствующие различным
объектам в обоих направлениях -

165
00:09:11,550 --> 00:09:13,730
возрастающем
и убывающем.

166
00:09:13,730 --> 00:09:15,230
И вы поддерживаете
их упорядоченными.

167
00:09:15,230 --> 00:09:19,190
Поэтому сортировка - это
действительно важная процедура

168
00:09:19,190 --> 00:09:23,090
в довольно многих приложениях
любой сложности, которые ???

169
00:09:23,090 --> 00:09:26,780
Поэтому стоит взглянуть
на различные

170
00:09:26,780 --> 00:09:28,350
алгоритмы сортировки.

171
00:09:28,350 --> 00:09:30,432
И сегодня мы рассмотрим
несколько простых сортировок.

172
00:09:30,432 --> 00:09:31,890
Но если вы пойдете и
посмотрите в Википедии

173
00:09:31,890 --> 00:09:35,270
и поищите в Google,
вы увидите, что есть много

174
00:09:35,270 --> 00:09:38,030
видов сортировок, таких как
шейкерная сортировка,

175
00:09:38,030 --> 00:09:41,900
битонная сортировка и других.

176
00:09:41,900 --> 00:09:45,900
Есть причины, по которым
каждая из них существует.

177
00:09:45,900 --> 00:09:49,830
Потому что в определенных
случаях, они выигрывают

178
00:09:49,830 --> 00:09:53,055
на определенных входных данных
или определенных задачах.

179
00:09:53,055 --> 00:09:55,660


180
00:09:55,660 --> 00:09:59,470
Что ж, давайте посмотрим на
наш первый алгоритм сортировки.

181
00:09:59,470 --> 00:10:03,640
Я не буду писать код, 
но он будет в конспекте.

182
00:10:03,640 --> 00:10:08,860
И он есть в вашем ??????

183
00:10:08,860 --> 00:10:10,770
Я просто дам псевдокод

184
00:10:10,770 --> 00:10:13,750
и пройдусь по тому,
как выглядит сортировка вставками.

185
00:10:13,750 --> 00:10:17,460
Потому что цель, которую я преследую
описывая этот алгоритм для вас -

186
00:10:17,460 --> 00:10:20,756
проанализировать его сложность.

187
00:10:20,756 --> 00:10:22,130
Мы должны выполнить
немного вычислений,

188
00:10:22,130 --> 00:10:25,230
по отношению к этому
алгоритму, чтобы выяснить,

189
00:10:25,230 --> 00:10:28,610
как быстро он будет работать
и какова его сложность

190
00:10:28,610 --> 00:10:30,280
в худшем случае.

191
00:10:30,280 --> 00:10:32,585
Итак, что такое сортировка вставками?

192
00:10:32,585 --> 00:10:41,780
Для i равного 1, 2 и так далее до n,
на входных данных, которые мы сортируем

193
00:10:41,780 --> 00:10:46,600
мы собираемся сделать следующее -
мы поставим элемент A[i]

194
00:10:46,600 --> 00:10:48,470
в правильную позицию.

195
00:10:48,470 --> 00:10:51,170
И мы предполагаем,
что мы

196
00:10:51,170 --> 00:10:55,220
своего рода в середине
процесса сортировки, когда

197
00:10:55,220 --> 00:11:00,920
у нас есть отсортированный массив A
c индексами от 0 до i-1.

198
00:11:00,920 --> 00:11:04,340
И мы собираемся
расширить его до

199
00:11:04,340 --> 00:11:07,590
массива с i+1 элементом.

200
00:11:07,590 --> 00:11:09,650
И элемент A[i] будет вставлен.

201
00:11:09,650 --> 00:11:12,830
в правильную позицию.

202
00:11:12,830 --> 00:11:23,640
И мы собираемся сделать это,
попарно меняя элементы местами и

203
00:11:23,640 --> 00:11:32,730
ставя на правильную позицию
число, которое изначально находилось

204
00:11:32,730 --> 00:11:33,490
на месте A[i].

205
00:11:33,490 --> 00:11:36,050


206
00:11:36,050 --> 00:11:42,410
Давайте рассмотрим пример.

207
00:11:42,410 --> 00:11:44,840
Мы будем сортировать в
возрастающем порядке.

208
00:11:44,840 --> 00:11:45,885
Есть только шесть чисел.

209
00:11:45,885 --> 00:11:50,430


210
00:11:50,430 --> 00:11:54,805
И изначально у нас есть
5, 2, 4, 6, 1, 3.

211
00:11:54,805 --> 00:11:56,430
Взглянем на эти числа.

212
00:11:56,430 --> 00:12:00,550
Вы начинаете с индекса 1,
то есть со второго элемента,

213
00:12:00,550 --> 00:12:03,620
потому что самый
первый элемент - он один

214
00:12:03,620 --> 00:12:06,050
и он уже отсортирован
по определению.

215
00:12:06,050 --> 00:12:07,930
Так что вы начинаете отсюда.

216
00:12:07,930 --> 00:12:10,890
И это то, что мы
называем нашим ключом.

217
00:12:10,890 --> 00:12:15,250
И это, на самом деле, указатель на то
место, где мы стоим прямо сейчас.

218
00:12:15,250 --> 00:12:17,020
И ключ продолжает
двигаться вправо

219
00:12:17,020 --> 00:12:20,007
когда мы проходим различные
шаги алгоритма.

220
00:12:20,007 --> 00:12:21,590
И вот что вы делаете - 
вы смотрите сюда

221
00:12:21,590 --> 00:12:24,830
и у вас есть элемент A[i].

222
00:12:24,830 --> 00:12:26,030
Это ваш ключ.

223
00:12:26,030 --> 00:12:30,070
И у вас есть массив A с индексами
от 0 до 0, то есть из одного элемента 5.

224
00:12:30,070 --> 00:12:34,260
И так как мы хотим сортировать
в возрастающем порядке,

225
00:12:34,260 --> 00:12:35,940
он неупорядочен.

226
00:12:35,940 --> 00:12:37,720
И поэтому мы меняем
элементы местами.

227
00:12:37,720 --> 00:12:42,400
То есть на этом шаге
мы меняем их местами.

228
00:12:42,400 --> 00:12:51,830
И мы бы получили
2, 5, 4, 6, 1, 3.

229
00:12:51,830 --> 00:12:55,080
Все это произошло здесь,
на этом шаге - на самом

230
00:12:55,080 --> 00:12:57,360
первом шаге, когда ключ был
на второй позиции -

231
00:12:57,360 --> 00:13:00,020
мы поменяли элементы местами.

232
00:13:00,020 --> 00:13:03,340
Теперь, ваш ключ здесь,
на элементе 4.

233
00:13:03,340 --> 00:13:05,980
Опять же, вы должны поместить
число 4 в правильное место.

234
00:13:05,980 --> 00:13:08,670
И поэтому вы меняете
элементы местами.

235
00:13:08,670 --> 00:13:11,280
И в этом случае вы
делаете один обмен.

236
00:13:11,280 --> 00:13:12,750
И получаете 2, 4, 5.

237
00:13:12,750 --> 00:13:15,650
И эта итерация закончена.

238
00:13:15,650 --> 00:13:27,850
Теперь у вас есть
элементы 2, 4, 5, 6, 1, 3.

239
00:13:27,850 --> 00:13:33,010
И теперь, ключ здесь,
на элементе 6.

240
00:13:33,010 --> 00:13:37,860
Теперь, вещи
становятся легкими,

241
00:13:37,860 --> 00:13:41,180
в смысле того, что вы смотрите
на него и говорите, что ж,

242
00:13:41,180 --> 00:13:43,480
я знаю, что эта часть
уже упорядочена.

243
00:13:43,480 --> 00:13:44,970
Число 6 больше 5.

244
00:13:44,970 --> 00:13:47,000
Поэтому ничего делать не нужно.

245
00:13:47,000 --> 00:13:51,530
Поэтому на этом шаге вы
не делаете обменов.

246
00:13:51,530 --> 00:13:56,440
Итак, все что
происходит здесь - это

247
00:13:56,440 --> 00:14:02,280
перемещение ключа
на один шаг вправо.

248
00:14:02,280 --> 00:14:06,370
Итак, мы получаем 2, 4, 5, 6, 1, 3.

249
00:14:06,370 --> 00:14:10,270
И сейчас ключ
на элементе 1.

250
00:14:10,270 --> 00:14:11,910
Здесь вы должны сделать
чуть больше работы.

251
00:14:11,910 --> 00:14:16,770
Теперь вы видите один аспект
сложности этого алгоритма -

252
00:14:16,770 --> 00:14:19,470
имея это, вы делаете обмены
элементов местами - способ,

253
00:14:19,470 --> 00:14:23,420
которым алгоритм
определен, на псевдокоде,

254
00:14:23,420 --> 00:14:27,760
going to use pairwise swaps
to find the correct position.

255
00:14:27,760 --> 00:14:29,640
Поэтому то,
что вы делаете -

256
00:14:29,640 --> 00:14:34,080
вы должны поменять
первую 1 и 6.

257
00:14:34,080 --> 00:14:36,310
И тогда вы поменяете -
1 вот здесь.

258
00:14:36,310 --> 00:14:39,970
Итак, вы меняете элементы
на этой позиции и на этой.

259
00:14:39,970 --> 00:14:44,580
And then you'll
swap-- essentially,

260
00:14:44,580 --> 00:14:49,910
do 4 swaps to get to
the point where you have

261
00:14:49,910 --> 00:14:52,970
1, 2, 4, 5, 6, 3.

262
00:14:52,970 --> 00:14:56,650
И это то, что получилось.

263
00:14:56,650 --> 00:14:59,190


264
00:14:59,190 --> 00:15:03,770
1, 2, 4, 5, 6, 3.

265
00:15:03,770 --> 00:15:06,360
Здесь важно
понять одну вещь.

266
00:15:06,360 --> 00:15:09,050
То что вы сделали 4
обмена, чтобы поставить 1

267
00:15:09,050 --> 00:15:10,160
на верную позицию.

268
00:15:10,160 --> 00:15:12,480
Теперь, вы могли бы представить
другую структуру данных,

269
00:15:12,480 --> 00:15:15,470
в которой вы двигаете это
сюда и сдигаете все

270
00:15:15,470 --> 00:15:16,930
направо.

271
00:15:16,930 --> 00:15:20,230
Но на самом деле, этот сдвиг
этих четырех элементов

272
00:15:20,230 --> 00:15:23,630
будет посчитан в нашей
модели как четыре

273
00:15:23,630 --> 00:15:26,244
операции, или четыре
шага, неважно.

274
00:15:26,244 --> 00:15:27,910
Потому что в
любом случае

275
00:15:27,910 --> 00:15:30,660
вам нужно проделать
здесь четыре вещи.

276
00:15:30,660 --> 00:15:36,830
И способ, которым код, тот что мы
используем в сортировке вставками,

277
00:15:36,830 --> 00:15:39,400
делает это - это
попарный обмен элементов.

278
00:15:39,400 --> 00:15:41,470
Итак, мы почти закончили.

279
00:15:41,470 --> 00:15:49,490
Теперь, ключ указывает на элемент 3.

280
00:15:49,490 --> 00:15:52,910
И теперь мы должны
поместить 3 в правильное место.

281
00:15:52,910 --> 00:15:55,350
Поэтому вам нужно
сделать несколько обменов.

282
00:15:55,350 --> 00:15:58,320
Это последний шаг.

283
00:15:58,320 --> 00:16:03,580
На этом шаге
мы меняем 3 с 6.

284
00:16:03,580 --> 00:16:06,520
Затем нужно
поменять 3 с 5.

285
00:16:06,520 --> 00:16:09,770
Затем нужно
поменять 3 с 4.

286
00:16:09,770 --> 00:16:12,985
И затем, так как 3 больше 2,
мы заканчиваем.

287
00:16:12,985 --> 00:16:16,325
Поэтому вы получаете 1, 2, 3, 4, 5, 6.

288
00:16:16,325 --> 00:16:18,880


289
00:16:18,880 --> 00:16:21,180
И все.

290
00:16:21,180 --> 00:16:22,820
Итак, теперь анализ.

291
00:16:22,820 --> 00:16:25,380


292
00:16:25,380 --> 00:16:26,630
Как много шагов я сделал?

293
00:16:26,630 --> 00:16:30,670


294
00:16:30,670 --> 00:16:32,150
АУДИТОРИЯ: n квадрат?

295
00:16:32,150 --> 00:16:36,310
ПРОФЕССОР: Нет, как
много шагов я сделал?

296
00:16:36,310 --> 00:16:40,120
Я думаю, что это не
очень хороший вопрос.

297
00:16:40,120 --> 00:16:43,930
Если я думаю о шаге,
как о перемещении ключа,

298
00:16:43,930 --> 00:16:46,215
как много шагов я сделал?

299
00:16:46,215 --> 00:16:49,930
Я сделал TETA(n) шагов.

300
00:16:49,930 --> 00:16:56,570
И в этом случае, вы можете
думать об этом, как о n-1 шаге.

301
00:16:56,570 --> 00:16:58,030
если стартуете с элемента 2.

302
00:16:58,030 --> 00:17:03,900
Но давайте скажем,
что это Тета(эн) шагов,

303
00:17:03,900 --> 00:17:06,780
в терминах позиций ключа.

304
00:17:06,780 --> 00:17:10,060


305
00:17:10,060 --> 00:17:11,150
И вы правы.

306
00:17:11,150 --> 00:17:15,349
Это н квадрат потому что,
на каждом шаге,

307
00:17:15,349 --> 00:17:19,730
возможна ситуация, когда
мне нужно выполнить порядка тета(н) работу.

308
00:17:19,730 --> 00:17:22,400
И один пример - этот,
прямо здесь,

309
00:17:22,400 --> 00:17:25,160
где я сделал 4 обмена.

310
00:17:25,160 --> 00:17:27,599
И в общем, вы можете
создать сценарий

311
00:17:27,599 --> 00:17:31,470
в котором, к концу работы
алгоритма.

312
00:17:31,470 --> 00:17:34,120
вы бы проделали тета(н) работы.

313
00:17:34,120 --> 00:17:37,560
Но если бы у вас был список, который
отсортирован в обратном порядке.

314
00:17:37,560 --> 00:17:40,960
Вы бы, в действительности, 
должны были сделать в среднем n

315
00:17:40,960 --> 00:17:43,850
by two swaps as you go
through each of the steps.

316
00:17:43,850 --> 00:17:45,300
Это и есть Тета(н).

317
00:17:45,300 --> 00:17:52,150
Поэтому на каждом шаге
мы делаем тета(н) шагов.

318
00:17:52,150 --> 00:17:55,930


319
00:17:55,930 --> 00:17:58,740
И когда я говорю обмены,
я мог бы также сказать,

320
00:17:58,740 --> 00:18:06,645
что на каждом шаге мы
делаем н сравнений и обменов.

321
00:18:06,645 --> 00:18:08,020
И это должно быть важно,

322
00:18:08,020 --> 00:18:10,430
потому что я должен задать
вам интересный вопрос

323
00:18:10,430 --> 00:18:11,700
через минуту.

324
00:18:11,700 --> 00:18:13,840
Но позвольте мне подытожить.

325
00:18:13,840 --> 00:18:16,470
У нас есть квадратичный алгоримт.

326
00:18:16,470 --> 00:18:17,970
Причина, по которой
это так, в том, что

327
00:18:17,970 --> 00:18:22,760
у меня есть
тета(н) шагов

328
00:18:22,760 --> 00:18:26,860
и каждый шаг
стоит тета(н).

329
00:18:26,860 --> 00:18:29,140
Когда я считаю,
что я считаю

330
00:18:29,140 --> 00:18:30,730
в терминах операций?

331
00:18:30,730 --> 00:18:33,510
Предположение, негласное
предположение в том, что

332
00:18:33,510 --> 00:18:36,810
операция состоит
из сравнения и обмена

333
00:18:36,810 --> 00:18:39,540
и они стоят одинаково.

334
00:18:39,540 --> 00:18:41,850
Для большинства
компьютеров это так.

335
00:18:41,850 --> 00:18:45,210
You have a single
instruction and, say, the x86

336
00:18:45,210 --> 00:18:47,700
or the MIPS architecture
that can do a compare,

337
00:18:47,700 --> 00:18:50,660
and the same thing for
swapping registers.

338
00:18:50,660 --> 00:18:52,640
Поэтому прекрасное предположение то,

339
00:18:52,640 --> 00:18:56,480
что сравнения и
обмены для чисел

340
00:18:56,480 --> 00:18:58,410
имеют одинаковую
стоимость.

341
00:18:58,410 --> 00:19:01,900
But if you had a record and
you were comparing records,

342
00:19:01,900 --> 00:19:05,700
and the comparison function that
you used for the records was

343
00:19:05,700 --> 00:19:08,820
in itself a method
call or a subroutine,

344
00:19:08,820 --> 00:19:11,290
it's quite possible
that all you're doing

345
00:19:11,290 --> 00:19:15,600
is swapping pointers or
references to do the swap,

346
00:19:15,600 --> 00:19:17,985
but the comparison could be
substantially more expensive.

347
00:19:17,985 --> 00:19:22,870


348
00:19:22,870 --> 00:19:24,920
Most of the time-- and
we'll differentiate

349
00:19:24,920 --> 00:19:27,150
if it becomes
necessary-- we're going

350
00:19:27,150 --> 00:19:29,560
to be counting comparisons
in the sorting algorithms

351
00:19:29,560 --> 00:19:31,230
that we'll be putting out.

352
00:19:31,230 --> 00:19:36,130
And we'll be assuming that
either comparison swaps are

353
00:19:36,130 --> 00:19:41,040
roughly the same or
that compares are--

354
00:19:41,040 --> 00:19:44,570
and we'll say which one,
of course-- that compares

355
00:19:44,570 --> 00:19:47,830
are substantially more
expensive than swaps.

356
00:19:47,830 --> 00:19:52,270
So if you had either of those
cases for insertion sort,

357
00:19:52,270 --> 00:19:54,226
you have a theta n
squared algorithm.

358
00:19:54,226 --> 00:19:55,600
You have theta n
squared compares

359
00:19:55,600 --> 00:19:58,200
and theta n squared swaps.

360
00:19:58,200 --> 00:20:00,780
Now, here's a question.

361
00:20:00,780 --> 00:20:11,179
Let's say that compares are
more expensive than swaps.

362
00:20:11,179 --> 00:20:12,720
And so, I'm concerned
about the theta

363
00:20:12,720 --> 00:20:14,750
n squared comparison cost.

364
00:20:14,750 --> 00:20:17,270


365
00:20:17,270 --> 00:20:20,880
I'm not as concerned, because of
the constant factors involved,

366
00:20:20,880 --> 00:20:22,710
with the theta n
squared swap cost.

367
00:20:22,710 --> 00:20:25,410


368
00:20:25,410 --> 00:20:28,730
This is a question question.

369
00:20:28,730 --> 00:20:33,590
What's a simple fix-- change
to this algorithm that

370
00:20:33,590 --> 00:20:37,260
would give me a better
complexity in the case

371
00:20:37,260 --> 00:20:39,900
where compares are
more expensive,

372
00:20:39,900 --> 00:20:43,300
or I'm only looking at the
complexity of compares.

373
00:20:43,300 --> 00:20:46,990
So the theta
whatever of compares.

374
00:20:46,990 --> 00:20:47,950
Anyone?

375
00:20:47,950 --> 00:20:48,661
Yeah, back there.

376
00:20:48,661 --> 00:20:49,536
AUDIENCE: [INAUDIBLE]

377
00:20:49,536 --> 00:20:56,356


378
00:20:56,356 --> 00:20:58,230
PROFESSOR: You could
compare with the middle.

379
00:20:58,230 --> 00:20:59,021
What did I call it?

380
00:20:59,021 --> 00:21:01,910


381
00:21:01,910 --> 00:21:03,120
I called it something.

382
00:21:03,120 --> 00:21:06,161
What you just said, I
called it something.

383
00:21:06,161 --> 00:21:07,160
AUDIENCE: Binary search.

384
00:21:07,160 --> 00:21:07,740
PROFESSOR: Binary search.

385
00:21:07,740 --> 00:21:08,310
That's right.

386
00:21:08,310 --> 00:21:10,280
Two cushions for this one.

387
00:21:10,280 --> 00:21:12,221
So you pick them
up after lecture.

388
00:21:12,221 --> 00:21:13,220
So you're exactly right.

389
00:21:13,220 --> 00:21:13,928
You got it right.

390
00:21:13,928 --> 00:21:18,160
I called it binary
search, up here.

391
00:21:18,160 --> 00:21:21,620
And so you can
take insertion sort

392
00:21:21,620 --> 00:21:24,800
and you can sort of trivially
turn it into a theta n log n

393
00:21:24,800 --> 00:21:27,200
algorithm if we
are talking about n

394
00:21:27,200 --> 00:21:29,910
being the number of compares.

395
00:21:29,910 --> 00:21:32,425
And all you have to do
to do that is to say,

396
00:21:32,425 --> 00:21:34,280
you know what, I'm
going to replace

397
00:21:34,280 --> 00:21:37,950
this with binary search.

398
00:21:37,950 --> 00:21:42,720
And you can do that-- and
that was the key observation--

399
00:21:42,720 --> 00:21:47,990
because A of 0 through i
minus 1 is already sorted.

400
00:21:47,990 --> 00:21:51,909
And so you can do binary search
on that part of the array.

401
00:21:51,909 --> 00:21:53,200
So let me just write that down.

402
00:21:53,200 --> 00:21:56,750


403
00:21:56,750 --> 00:22:04,000
Do a binary search on A
of 0 through i minus 1,

404
00:22:04,000 --> 00:22:05,095
which is already sorted.

405
00:22:05,095 --> 00:22:10,540


406
00:22:10,540 --> 00:22:16,780
And essentially, you can think
of it as theta log i time,

407
00:22:16,780 --> 00:22:18,070
and for each of those steps.

408
00:22:18,070 --> 00:22:27,251
And so then you get your
theta n log n theta n log

409
00:22:27,251 --> 00:22:30,410
n in terms of compares.

410
00:22:30,410 --> 00:22:37,940
Does this help the swaps
for an array data structure?

411
00:22:37,940 --> 00:22:41,280
No, because binary search
will require insertion

412
00:22:41,280 --> 00:22:44,670
into A of 0 though i minus 1.

413
00:22:44,670 --> 00:22:45,880
So here's the problem.

414
00:22:45,880 --> 00:22:50,430
Why don't we have a full-fledged
theta n log n algorithm,

415
00:22:50,430 --> 00:22:53,940
regardless of the cost
of compares or swaps?

416
00:22:53,940 --> 00:22:55,470
We don't quite have that.

417
00:22:55,470 --> 00:23:02,950
We don't quite have that because
we need to insert our A of i

418
00:23:02,950 --> 00:23:07,850
into the right position into
A of 0 through i minus 1.

419
00:23:07,850 --> 00:23:09,790
You do that if you have
an array structure,

420
00:23:09,790 --> 00:23:10,998
it might get into the middle.

421
00:23:10,998 --> 00:23:13,337
And you have to shift
things over to the right.

422
00:23:13,337 --> 00:23:15,170
And when you shift
things over to the right,

423
00:23:15,170 --> 00:23:17,090
in the worst case, you may
be shifting a lot of things

424
00:23:17,090 --> 00:23:17,980
over to the right.

425
00:23:17,980 --> 00:23:20,630
And that gets back to worst
case complexity of theta n.

426
00:23:20,630 --> 00:23:23,200


427
00:23:23,200 --> 00:23:27,000
So a binary search
in insertion sort

428
00:23:27,000 --> 00:23:29,197
gives you theta n
log n for compares.

429
00:23:29,197 --> 00:23:30,905
But it's still theta
n squared for swaps.

430
00:23:30,905 --> 00:23:35,000


431
00:23:35,000 --> 00:23:36,805
So as you can see,
there's many varieties

432
00:23:36,805 --> 00:23:37,770
of sorting algorithms.

433
00:23:37,770 --> 00:23:39,850
We just looked at
a couple of them.

434
00:23:39,850 --> 00:23:43,010
And they were both
insertion sort.

435
00:23:43,010 --> 00:23:45,040
The second one
that I just put up

436
00:23:45,040 --> 00:23:48,900
is, I guess, technically
called binary insertion sort

437
00:23:48,900 --> 00:23:50,710
because it does binary search.

438
00:23:50,710 --> 00:23:53,000
And the vanilla
insertion sort is

439
00:23:53,000 --> 00:23:56,676
the one that you have the code
for in the doc dis program,

440
00:23:56,676 --> 00:23:59,400
or at least one of
the doc dis files.

441
00:23:59,400 --> 00:24:04,620
So let's move on and talk
about a different algorithm.

442
00:24:04,620 --> 00:24:06,830
So what we'd like to
do, now-- this class

443
00:24:06,830 --> 00:24:09,120
is about constant improvement.

444
00:24:09,120 --> 00:24:11,480
We're never happy.

445
00:24:11,480 --> 00:24:14,370
We always want to do
a little bit better.

446
00:24:14,370 --> 00:24:16,864
And eventually, once
we run out of room

447
00:24:16,864 --> 00:24:18,280
from an asymptotic
standpoint, you

448
00:24:18,280 --> 00:24:20,363
take these other classes
where you try and improve

449
00:24:20,363 --> 00:24:24,380
constant factors and
get 10%, and 5%, and 1%,

450
00:24:24,380 --> 00:24:25,560
and so on, and so forth.

451
00:24:25,560 --> 00:24:31,200
But we'll stick to improving
asymptotic complexity.

452
00:24:31,200 --> 00:24:34,190
And we're not quite happy
with binary insertion sort

453
00:24:34,190 --> 00:24:37,050
because, in the case of numbers,
our binary insertion sort

454
00:24:37,050 --> 00:24:40,709
has theta n squared complexity,
if you look at swaps.

455
00:24:40,709 --> 00:24:43,042
So we'd like to go find an
algorithm that is theta n log

456
00:24:43,042 --> 00:24:44,810
n.

457
00:24:44,810 --> 00:24:49,600
And I guess, eventually,
we'll have to stop.

458
00:24:49,600 --> 00:24:51,260
But Erik will take care of that.

459
00:24:51,260 --> 00:24:53,900


460
00:24:53,900 --> 00:24:54,970
There's a reason to stop.

461
00:24:54,970 --> 00:24:58,620
It's when you can prove that
you can't do any better.

462
00:24:58,620 --> 00:25:01,210
And so we'll get to
that, eventually.

463
00:25:01,210 --> 00:25:04,685
So merge sort is also something
that you've probably seen.

464
00:25:04,685 --> 00:25:07,277


465
00:25:07,277 --> 00:25:08,735
But there probably
will be a couple

466
00:25:08,735 --> 00:25:12,440
of subtleties that come out as
I describe this algorithm that,

467
00:25:12,440 --> 00:25:15,340
hopefully, will be interesting
to those of you who already

468
00:25:15,340 --> 00:25:16,810
know merge sort.

469
00:25:16,810 --> 00:25:21,030
And for those of you who don't,
it's a very pretty algorithm.

470
00:25:21,030 --> 00:25:26,930
It's a standard recursion
algorithm-- recursive

471
00:25:26,930 --> 00:25:30,620
algorithm-- similar
to a binary search.

472
00:25:30,620 --> 00:25:34,780
What we do, here, is we have
an array, A. We split it

473
00:25:34,780 --> 00:25:42,095
into two parts, L and R.
And essentially, we kind of

474
00:25:42,095 --> 00:25:43,950
do no work, really.

475
00:25:43,950 --> 00:25:49,814
In terms of the L and R in
the sense that we just call,

476
00:25:49,814 --> 00:25:51,480
we keep splitting,
splitting, splitting.

477
00:25:51,480 --> 00:25:54,020
And all the work is
done down at the bottom

478
00:25:54,020 --> 00:25:57,570
in this routine called
merge, where we are merging

479
00:25:57,570 --> 00:26:00,110
a pair of elements
at the leaves.

480
00:26:00,110 --> 00:26:04,490
And then, we merge two
pairs and get four elements.

481
00:26:04,490 --> 00:26:08,630
And then we merge four tuples
of elements, et cetera,

482
00:26:08,630 --> 00:26:10,080
and go all the way up.

483
00:26:10,080 --> 00:26:18,990
So while I'm just saying L
terms into L prime, out here,

484
00:26:18,990 --> 00:26:20,990
there's no real
explicit code that you

485
00:26:20,990 --> 00:26:23,870
can see that turns
L into L prime.

486
00:26:23,870 --> 00:26:25,630
It happens really later.

487
00:26:25,630 --> 00:26:27,190
There's no real
sorting code, here.

488
00:26:27,190 --> 00:26:28,790
It happens in the merge routine.

489
00:26:28,790 --> 00:26:30,649
And you'll see
that quite clearly

490
00:26:30,649 --> 00:26:31,940
when we run through an example.

491
00:26:31,940 --> 00:26:34,960


492
00:26:34,960 --> 00:26:41,500
So you have L and R turn
into L prime and R prime.

493
00:26:41,500 --> 00:26:52,310
And what we end up getting
is a sorted array, A.

494
00:26:52,310 --> 00:26:58,900
And we have what's called
a merge routine that

495
00:26:58,900 --> 00:27:01,110
takes L prime and R
prime and merges them

496
00:27:01,110 --> 00:27:02,400
into the sorted array.

497
00:27:02,400 --> 00:27:09,270
So at the top level, what
you see is split into two,

498
00:27:09,270 --> 00:27:13,280
and do a merge, and get
to the sorted array.

499
00:27:13,280 --> 00:27:16,680
The input is of size n.

500
00:27:16,680 --> 00:27:24,690
You have two arrays
of size n over 2.

501
00:27:24,690 --> 00:27:33,210
Имеем два отсортированных
массива размера n/2.

502
00:27:33,210 --> 00:27:39,480
И тогда, наконец, у вас есть
массив размера n.

503
00:27:39,480 --> 00:27:42,116


504
00:27:42,116 --> 00:27:44,240
Итак, если вы хотите следоватть
рекурсии выполнения

505
00:27:44,240 --> 00:27:49,870
в этом маленьком
примере, тогда вы

506
00:27:49,870 --> 00:27:53,790
сможете увидеть,
как это работает.

507
00:27:53,790 --> 00:27:56,120
И мы рассмотрим относительно
простой пример

508
00:27:56,120 --> 00:27:58,200
с 8 элементами.

509
00:27:58,200 --> 00:28:03,180
Итак, на верхнем уровне -
до того, как мы придем сюда,

510
00:28:03,180 --> 00:28:08,640
слияние подразумевает, что у
вас есть два отсортированных массива,

511
00:28:08,640 --> 00:28:11,700
и слить их вместе.

512
00:28:11,700 --> 00:28:15,960
Это инвариант в сортировке слиянием,
или для процедуры слияния.

513
00:28:15,960 --> 00:28:19,570
Это подразумевает, что входы
отсортированы - L и R. На самом деле

514
00:28:19,570 --> 00:28:22,800
я должен сказать, L и R простые.

515
00:28:22,800 --> 00:28:27,624
Поэтому давайте скажем, что
у вас есть 20, 13, 7 и 2.

516
00:28:27,624 --> 00:28:31,320
У вас есть 12, 11, 9 и 1.

517
00:28:31,320 --> 00:28:33,400
И это могло быть L простым.

518
00:28:33,400 --> 00:28:36,840
И это могло быть R простым.

519
00:28:36,840 --> 00:28:39,650
Что у вас есть это то, что
мы называем алгоритм двух пальцев.

520
00:28:39,650 --> 00:28:42,380
И поэтому у вас есть два пальца
и каждый из них

521
00:28:42,380 --> 00:28:44,162
на что-то указывает.

522
00:28:44,162 --> 00:28:45,870
И в этом случае, один
из них указывает

523
00:28:45,870 --> 00:28:49,190
на L. Мой левый палец
указывает на простое L.

524
00:28:49,190 --> 00:28:50,800
или какой-то элемент
простой L.

525
00:28:50,800 --> 00:28:53,850
Мой правый палец указывает
на какой-то элемент в R правом.

526
00:28:53,850 --> 00:28:56,820
И я собираюсь сравнить два
элемента

527
00:28:56,820 --> 00:28:58,740
на которые указывают
мои пальцы.

528
00:28:58,740 --> 00:29:02,170
И я собираюсь выбрать,
в этом случае,

529
00:29:02,170 --> 00:29:03,840
наименьший из этих
элементов.

530
00:29:03,840 --> 00:29:07,790
И я собираюсь поместить
их в отсортированный массив.

531
00:29:07,790 --> 00:29:10,970
Поэтому начнем отсюда.

532
00:29:10,970 --> 00:29:12,480
Посмотрите сюда и сюда.

533
00:29:12,480 --> 00:29:14,266
И я сравнил 2 и 1.

534
00:29:14,266 --> 00:29:15,140
Какое из них меньше?

535
00:29:15,140 --> 00:29:16,310
1 меньше.

536
00:29:16,310 --> 00:29:19,130
Итак я собираюсь записать 1.

537
00:29:19,130 --> 00:29:23,720
Это двухпальцевый алгоритм для слияния.

538
00:29:23,720 --> 00:29:24,880
И я записываю 1.

539
00:29:24,880 --> 00:29:27,380
Когда я записываю 1, я
я зачеркиваю 1.

540
00:29:27,380 --> 00:29:29,395
То есть, эффективно,
здесь происходит следующее -

541
00:29:29,395 --> 00:29:31,460
позвольте мне просто обвести
число вместо зачеркивания.

542
00:29:31,460 --> 00:29:35,450
И мой палец перемещается к 9.

543
00:29:35,450 --> 00:29:38,110
Сейчас я указываю на 2 и 9.

544
00:29:38,110 --> 00:29:40,080
И я повторяю этот шаг.

545
00:29:40,080 --> 00:29:41,870
Итак, теперь, в этом случае
2 меньше.

546
00:29:41,870 --> 00:29:44,040
Поэтому я собираюсь пойти
дальше и записать 2.

547
00:29:44,040 --> 00:29:49,420
И я могу зачеркнуть 2
и переместить мой палец на 7.

548
00:29:49,420 --> 00:29:50,840
И это все.

549
00:29:50,840 --> 00:29:54,010
Я не буду проходить
через оставшиеся шаги.

550
00:29:54,010 --> 00:29:56,114
Это в действительности подъем.

551
00:29:56,114 --> 00:29:57,780
У вас есть пара
указателей и вы

552
00:29:57,780 --> 00:29:59,920
проходите по двум массивам.

553
00:29:59,920 --> 00:30:07,230
И выписываете 1,
2, 7, 9, 11, 12, 13, 20.

554
00:30:07,230 --> 00:30:08,730
Это ваша процедура слияния.

555
00:30:08,730 --> 00:30:12,330
И, на самом деле, вся работа
делается в процедуре слияния,

556
00:30:12,330 --> 00:30:15,460
потому что все остальное
это просто

557
00:30:15,460 --> 00:30:16,620
рекурсивный вызов.

558
00:30:16,620 --> 00:30:18,420
Конечно, вам нужно
разбить массив.

559
00:30:18,420 --> 00:30:20,110
Но это
довольно просто.

560
00:30:20,110 --> 00:30:24,600
Если у вас есть массив A, с индексами
от 0 до n, тогда, в зависимости от того,

561
00:30:24,600 --> 00:30:28,300
четное n или нечетное, вы
можете представить, что L это

562
00:30:28,300 --> 00:30:38,530
массив A от 0 до n/2 - 1,

563
00:30:38,530 --> 00:30:41,420
и похожим образом для R.

564
00:30:41,420 --> 00:30:44,086
Поэтому вы просто разбиваете
его напопалам в середине.

565
00:30:44,086 --> 00:30:45,710
Я поговорю об
этом подробенн.

566
00:30:45,710 --> 00:30:47,334
There's a subtlety
associated with that

567
00:30:47,334 --> 00:30:51,200
that we'll get to
in a few minutes.

568
00:30:51,200 --> 00:30:55,280
But to finish up in terms of
the computation of merge sort.

569
00:30:55,280 --> 00:30:56,110
Это все.

570
00:30:56,110 --> 00:31:00,827
Процедура слияния делает
большую часть, если не всю, работу.

571
00:31:00,827 --> 00:31:02,410
И этот двухпальцевый
алгоритм может

572
00:31:02,410 --> 00:31:04,630
взять два отсортированных
массива

573
00:31:04,630 --> 00:31:09,550
и сложить их в единый
отсортированный массив.

574
00:31:09,550 --> 00:31:13,150
by interspersing, or
interleaving, these elements.

575
00:31:13,150 --> 00:31:15,000
И какая сложность
слияния,

576
00:31:15,000 --> 00:31:18,710
если у меня есть
два массива размера n/2?

577
00:31:18,710 --> 00:31:21,810
Что я получаю?

578
00:31:21,810 --> 00:31:22,590
АУДИТОРИЯ: n.

579
00:31:22,590 --> 00:31:23,731
ПРОФЕССОР: n.

580
00:31:23,731 --> 00:31:24,980
Мы дадим подушку и вам.

581
00:31:24,980 --> 00:31:28,050


582
00:31:28,050 --> 00:31:29,165
Сложность Тета(n).

583
00:31:29,165 --> 00:31:35,470


584
00:31:35,470 --> 00:31:36,290
Пока все хорошо.

585
00:31:36,290 --> 00:31:38,830


586
00:31:38,830 --> 00:31:41,640
Я знаю, что вы
знаете, какая

587
00:31:41,640 --> 00:31:43,550
сложность у сортировки слиянием.

588
00:31:43,550 --> 00:31:45,180
Но я думаю, что
большинство из вас

589
00:31:45,180 --> 00:31:47,900
не сможет доказать это мне,
потому что я очень требователен

590
00:31:47,900 --> 00:31:50,920
к доказательствам чего-либо.

591
00:31:50,920 --> 00:31:53,040
Я всегда могу
сказать: "Я вам не верю".

592
00:31:53,040 --> 00:31:53,956
Или: "Я вас не понимаю".

593
00:31:53,956 --> 00:31:57,960


594
00:31:57,960 --> 00:32:00,880
Сложность, вы
уже говорили это,

595
00:32:00,880 --> 00:32:02,580
и, я думаю,
Эрик упоминал это, -

596
00:32:02,580 --> 00:32:08,370
общая сложность этого
алгоритма - ТЕТА(n * log(n)).

597
00:32:08,370 --> 00:32:09,810
Почему так получается?

598
00:32:09,810 --> 00:32:11,790
Как это можно доказать?

599
00:32:11,790 --> 00:32:16,840
И что мы сейчас сделаем? Сейчас мы
посмотрим на сортировку слиянием.

600
00:32:16,840 --> 00:32:19,070
Мы рассмотрим
дерево рекурсии.

601
00:32:19,070 --> 00:32:20,695
И мы попробуем доказать это.
Есть много способов

602
00:32:20,695 --> 00:32:23,370
доказать то, что сложность
сортировки слиянием ТЕТА(n*log(n)).

603
00:32:23,370 --> 00:32:25,860
Способ, которым 
будем использовать мы,

604
00:32:25,860 --> 00:32:28,640
называется доказательством
картинкой.

605
00:32:28,640 --> 00:32:32,290
Это не формальное
техника доказательства,

606
00:32:32,290 --> 00:32:35,020
но это что-то, что
очень помагает

607
00:32:35,020 --> 00:32:38,100
получить интуицию
на фоне доказательства

608
00:32:38,100 --> 00:32:40,441
и почему результат правильный.

609
00:32:40,441 --> 00:32:41,940
И вы всегда можете
взять это и вы можете

610
00:32:41,940 --> 00:32:47,030
формализовать это
и сделать это чем-то

611
00:32:47,030 --> 00:32:49,680
во что поверит каждый.

612
00:32:49,680 --> 00:32:52,960
И мы также взглянем
на подстановку, возможно,

613
00:32:52,960 --> 00:32:56,310
в секции завтра,
для решения рекуррентного соотношения.

614
00:32:56,310 --> 00:33:00,540
Итак, мы правы в том, что
мы имеем алгоритм

615
00:33:00,540 --> 00:33:07,710
"разделяй и властвуй" с шагом
слияния, работающим за Тета(n).

616
00:33:07,710 --> 00:33:12,540
И поэтому, если я просто посмотрю
на эту структуру, которая у меня есть

617
00:33:12,540 --> 00:33:16,150
Я могу записать реккуретное
соотношение для сортировки

618
00:33:16,150 --> 00:33:17,966
слиянием, которое
выглядит вот так.

619
00:33:17,966 --> 00:33:22,720
Поэтому, когда я говорю
о сложности, я могу сказать,

620
00:33:22,720 --> 00:33:26,230
что она составляла Т(n),
для работы из n элементов.

621
00:33:26,230 --> 00:33:28,910
будет каким-то константным
временем в порядке

622
00:33:28,910 --> 00:33:31,940
деления массива.

623
00:33:31,940 --> 00:33:34,200
Поэтому это может быть
частью, соответствующей

624
00:33:34,200 --> 00:33:36,360
разделению массива.

625
00:33:36,360 --> 00:33:40,360
И есть 2 задачи
размера n/2.

626
00:33:40,360 --> 00:33:42,810
Поэтому у меня есть 2T(n/2).

627
00:33:42,810 --> 00:33:44,710
Это рекурсивная часть.

628
00:33:44,710 --> 00:33:48,650


629
00:33:48,650 --> 00:33:53,960
И я получу c*n,
соответсвующее слиянию.

630
00:33:53,960 --> 00:33:58,910
И это какая-то константа умноженная
на n, что мы имеем здесь,

631
00:33:58,910 --> 00:34:01,890
по отношению к сложности
Тета(n).

632
00:34:01,890 --> 00:34:04,980
Итак у вас есть рекуррентное соотношение
как это и я знаю некоторые из вас

633
00:34:04,980 --> 00:34:07,150
уже видели рекуррентные
соотношения в курсе 6.042.

634
00:34:07,150 --> 00:34:09,239
И вы знаете, как их решать.

635
00:34:09,239 --> 00:34:14,469
Что бы я хотел сделать - это показать
вам дервево рекурсии

636
00:34:14,469 --> 00:34:17,989
не только сказать вам как
решать эти неравенства,

637
00:34:17,989 --> 00:34:23,102
но также дать вам понятие того,
как решать рекуррентные соотношения,

638
00:34:23,102 --> 00:34:25,560
в которых вместо c*n, у вас что-то
другое здесь.

639
00:34:25,560 --> 00:34:27,790
У вас есть f(n), которая
является другой функцией

640
00:34:27,790 --> 00:34:29,280
от линейной фукнции.

641
00:34:29,280 --> 00:34:33,750
Это дерево рекурсии,
на мой взгляд, самый

642
00:34:33,750 --> 00:34:38,650
простой способ доказать
то, что сложность

643
00:34:38,650 --> 00:34:41,100
сортировки слиянием
равна ТЕТА(n*log(n)).

644
00:34:41,100 --> 00:34:44,339
Теперь я хочу раскрыть
рекуррентное соотношение.

645
00:34:44,339 --> 00:34:45,505
Давайте сделаем это вот здесь.

646
00:34:45,505 --> 00:35:06,830


647
00:35:06,830 --> 00:35:10,950
Поэтому я имею c*n
на высоком уровне.

648
00:35:10,950 --> 00:35:15,850
Я собираюсь игнорировать
этот константный множитель,

649
00:35:15,850 --> 00:35:16,550
потому что c*n преобладает.

650
00:35:16,550 --> 00:35:18,080
Поэтому я просто начну
с c*n.

651
00:35:18,080 --> 00:35:23,450
Я хочу разбить вещи, так,
как во время рекурсии.

652
00:35:23,450 --> 00:35:26,960
Поэтому когда я иду с c*n,
на высоком уровне - эта работа

653
00:35:26,960 --> 00:35:29,750
которую я должен сделать
при слиянии, на высоком уровне.

654
00:35:29,750 --> 00:35:33,110
И после, когда я спускаюсь
до двух меньших проблем, каждая

655
00:35:33,110 --> 00:35:34,480
из которых размера n/2.

656
00:35:34,480 --> 00:35:38,440
Поэтому я делаю
c*n деленное пополам.

657
00:35:38,440 --> 00:35:41,617
Поэтому это просто
константа c.

658
00:35:41,617 --> 00:35:43,200
Я не хотел писать
Тета здесь.

659
00:35:43,200 --> 00:35:44,440
Вы можете.

660
00:35:44,440 --> 00:35:46,760
И я скажу чуть больше об этом позже.

661
00:35:46,760 --> 00:35:49,180
Но думайте об этом c*n как
представленной Тета(n)

662
00:35:49,180 --> 00:35:50,260
сложности.

663
00:35:50,260 --> 00:35:52,790
И c это константа.

664
00:35:52,790 --> 00:35:57,960
So c times n, here. c
times n over 2, here.

665
00:35:57,960 --> 00:36:01,760
And then when I keep going,
I have c times n over 4,

666
00:36:01,760 --> 00:36:08,910
c times n over 4, et cetera,
and so on, and so forth.

667
00:36:08,910 --> 00:36:10,650
And when I come down
all the way here,

668
00:36:10,650 --> 00:36:16,670
n is eventually going to become
1-- or essentially a constant--

669
00:36:16,670 --> 00:36:20,790
and I'm going to have
a bunch of c's here.

670
00:36:20,790 --> 00:36:27,050
So here's another question,
that I'd like you to answer.

671
00:36:27,050 --> 00:36:31,210
Someone tell me what the number
of levels in this tree are,

672
00:36:31,210 --> 00:36:34,060
precisely, and the number
of leaves in this tree are,

673
00:36:34,060 --> 00:36:35,570
precisely.

674
00:36:35,570 --> 00:36:38,061
AUDIENCE: The number of
levels is log n plus 1.

675
00:36:38,061 --> 00:36:39,060
PROFESSOR: Log n plus 1.

676
00:36:39,060 --> 00:36:41,169
Log to the base 2 plus 1.

677
00:36:41,169 --> 00:36:42,210
And the number of leaves?

678
00:36:42,210 --> 00:36:48,430


679
00:36:48,430 --> 00:36:50,580
You raised your hand
back there, first.

680
00:36:50,580 --> 00:36:51,430
Number of leaves.

681
00:36:51,430 --> 00:36:52,880
AUDIENCE: I think n.

682
00:36:52,880 --> 00:36:54,130
PROFESSOR: Yeah, you're right.

683
00:36:54,130 --> 00:36:56,210
You think right.

684
00:36:56,210 --> 00:37:02,520
So 1 plus log n and n leaves.

685
00:37:02,520 --> 00:37:05,870
When n becomes 1, how
many of them do you have?

686
00:37:05,870 --> 00:37:09,470
You're down to a single element,
which is, by definition,

687
00:37:09,470 --> 00:37:10,580
sorted.

688
00:37:10,580 --> 00:37:13,730
And you have n leaves.

689
00:37:13,730 --> 00:37:17,020
So now let's add up the work.

690
00:37:17,020 --> 00:37:20,230
I really like this
picture because it's just

691
00:37:20,230 --> 00:37:23,450
so intuitive in terms
of getting us the result

692
00:37:23,450 --> 00:37:25,090
that we're looking for.

693
00:37:25,090 --> 00:37:30,080
So you add up the work in each
of the levels of this tree.

694
00:37:30,080 --> 00:37:32,190
So the top level is cn.

695
00:37:32,190 --> 00:37:39,790
The second level is cn because
I added 1/2 and 1/2, cn, cn.

696
00:37:39,790 --> 00:37:40,750
Wow.

697
00:37:40,750 --> 00:37:43,010
What symmetry.

698
00:37:43,010 --> 00:37:50,500
So you're doing the same
amount of work modulo

699
00:37:50,500 --> 00:37:54,050
the constant factors,
here, with what's

700
00:37:54,050 --> 00:37:56,280
going on with the c1,
which we've ignored,

701
00:37:56,280 --> 00:37:59,870
but roughly the same amount
of work in each of the levels.

702
00:37:59,870 --> 00:38:02,570
And now, you know how
many levels there are.

703
00:38:02,570 --> 00:38:04,850
It's 1 plus log n.

704
00:38:04,850 --> 00:38:11,930
So if you want to write
an equation for T of n,

705
00:38:11,930 --> 00:38:23,030
it's 1 plus log n times c of
n, which is theta of n log n.

706
00:38:23,030 --> 00:38:26,520


707
00:38:26,520 --> 00:38:31,049
So I've mixed in
constants c and thetas.

708
00:38:31,049 --> 00:38:32,590
For the purposes of
this description,

709
00:38:32,590 --> 00:38:33,950
they're interchangeable.

710
00:38:33,950 --> 00:38:38,095
You will see recurrences that
look like this, in class.

711
00:38:38,095 --> 00:38:45,210


712
00:38:45,210 --> 00:38:46,860
And things like that.

713
00:38:46,860 --> 00:38:48,370
Не путайтесь.

714
00:38:48,370 --> 00:38:51,150
Это просто константный
мультипликативный множитель

715
00:38:51,150 --> 00:38:54,510
перед вашей функцией.

716
00:38:54,510 --> 00:38:56,230
And it's just a little
easier, I think,

717
00:38:56,230 --> 00:38:58,140
to write down these
constant factors

718
00:38:58,140 --> 00:39:00,510
and realize that the
amount of work done

719
00:39:00,510 --> 00:39:02,980
is the same in
each of the leaves.

720
00:39:02,980 --> 00:39:06,010
And once you know the
dimensions of this tree,

721
00:39:06,010 --> 00:39:08,930
in terms of levels and in
terms of the number of leaves,

722
00:39:08,930 --> 00:39:10,960
you get your result.

723
00:39:10,960 --> 00:39:14,560


724
00:39:14,560 --> 00:39:17,425
Что ж, мы рассмотрели
два алгоритма.

725
00:39:17,425 --> 00:39:26,160


726
00:39:26,160 --> 00:39:29,540
Сортировка вставками,
если говорить о числах,

727
00:39:29,540 --> 00:39:31,964
is theta n squared for swaps.

728
00:39:31,964 --> 00:39:33,130
Merge sort is theta n log n.

729
00:39:33,130 --> 00:39:36,270


730
00:39:36,270 --> 00:39:38,680
Еще один
интеренсый вопрос.

731
00:39:38,680 --> 00:39:44,720
В чем преимущество сортировки
вставками над сортировкой слиянием?

732
00:39:44,720 --> 00:39:50,176


733
00:39:50,176 --> 00:39:51,180
AUDIENCE: [INAUDIBLE]

734
00:39:51,180 --> 00:39:52,732
ПРОФЕССОР: И что это означает?

735
00:39:52,732 --> 00:39:54,773
AUDIENCE: You don't have
to move elements outside

736
00:39:54,773 --> 00:39:56,960
of [INAUDIBLE].

737
00:39:56,960 --> 00:39:58,420
ПРОФЕССОР: Это абсолютно верно.

738
00:39:58,420 --> 00:40:01,330
Это абсолютно верно.

739
00:40:01,330 --> 00:40:03,270
Двое ребят, которые до
этого ответили на вопросы

740
00:40:03,270 --> 00:40:05,840
с уровнями и вы.

741
00:40:05,840 --> 00:40:07,740
Подойдите ко мне после лекции.

742
00:40:07,740 --> 00:40:09,690
Это отличный ответ.

743
00:40:09,690 --> 00:40:12,180
It's in-place
sorting is something

744
00:40:12,180 --> 00:40:14,820
that has to do with
auxiliary space.

745
00:40:14,820 --> 00:40:19,280
And so what you see, here--
and it was a bit hidden, here.

746
00:40:19,280 --> 00:40:21,940
But the fact of the
matter is that you

747
00:40:21,940 --> 00:40:25,530
had L prime and R prime.

748
00:40:25,530 --> 00:40:29,910
And L prime and R prime are
different from L and R, which

749
00:40:29,910 --> 00:40:33,440
were the initial halves of
the inputs to the sorting

750
00:40:33,440 --> 00:40:34,990
algorithm.

751
00:40:34,990 --> 00:40:38,630
And what I said here is, we're
going to dump this into A.

752
00:40:38,630 --> 00:40:40,440
That's what this picture shows.

753
00:40:40,440 --> 00:40:43,340
This says sorted
array, A. And so you

754
00:40:43,340 --> 00:40:48,720
had to make a copy of the
array-- the two halves L

755
00:40:48,720 --> 00:40:52,270
and R-- in order to
do the recursion,

756
00:40:52,270 --> 00:40:54,490
and then to take the
results and put them

757
00:40:54,490 --> 00:40:56,790
into the sorted array, A.

758
00:40:56,790 --> 00:40:59,220
So you needed-- in
merge sort-- you

759
00:40:59,220 --> 00:41:04,060
needed theta n auxiliary space.

760
00:41:04,060 --> 00:41:10,370
So merge sort, you need
theta n extra space.

761
00:41:10,370 --> 00:41:17,380
And the definition
of in-place sorting

762
00:41:17,380 --> 00:41:21,575
implies that you have theta
1-- constant-- auxiliary space.

763
00:41:21,575 --> 00:41:24,580


764
00:41:24,580 --> 00:41:27,330
Вспомогательная пмять
для сортировки вставками

765
00:41:27,330 --> 00:41:30,450
это просто временная
переменная, которая нужна

766
00:41:30,450 --> 00:41:33,310
вам, когда вы меняете
два элемента местами.

767
00:41:33,310 --> 00:41:35,520
Когда вы хотите поменять
местами два регистра,

768
00:41:35,520 --> 00:41:38,070
вы сохраняете одно из значений
во временном хранилище,

769
00:41:38,070 --> 00:41:39,600
перезаписываете второе,
и так далее.

770
00:41:39,600 --> 00:41:43,190
Это и есть ТЕТА(1) вспомогательной
помяти в случае сортировки вставками.

771
00:41:43,190 --> 00:41:47,330
И это преимущество той версии
сортировки вставками, о которой

772
00:41:47,330 --> 00:41:49,140
мы говорили сегодня над
сортировкой слиянием.

773
00:41:49,140 --> 00:41:52,827
And if you have a billion
elements, that's potentially

774
00:41:52,827 --> 00:41:54,660
something you don't
want to store in memory.

775
00:41:54,660 --> 00:41:57,550
If you want to do something
really fast and do everything

776
00:41:57,550 --> 00:42:00,400
in cache or main
memory, and you want

777
00:42:00,400 --> 00:42:03,610
to sort billions are maybe
even trillions of items,

778
00:42:03,610 --> 00:42:07,740
this becomes an
important consideration.

779
00:42:07,740 --> 00:42:12,930
I will say that you can
reduce the constant factor

780
00:42:12,930 --> 00:42:14,530
of the theta n.

781
00:42:14,530 --> 00:42:16,590
So in the vanilla
scheme, you could

782
00:42:16,590 --> 00:42:18,690
imagine that you have to
have a copy of the array.

783
00:42:18,690 --> 00:42:20,900
So if you had n
elements, you essentially

784
00:42:20,900 --> 00:42:24,490
have n extra items of storage.

785
00:42:24,490 --> 00:42:28,130
You can make that n over 2
with a simple coding trick

786
00:42:28,130 --> 00:42:32,710
by keeping 1/2 of A.

787
00:42:32,710 --> 00:42:35,800
You can throw away one of
the L's or one of the R's.

788
00:42:35,800 --> 00:42:37,637
And you can get it
down to n over 2.

789
00:42:37,637 --> 00:42:39,470
And that turns out--
it's a reasonable thing

790
00:42:39,470 --> 00:42:41,410
to do if you have
a billion elements

791
00:42:41,410 --> 00:42:45,400
and you want to reduce your
storage by a constant factor.

792
00:42:45,400 --> 00:42:47,130
So that's one coding trick.

793
00:42:47,130 --> 00:42:49,630
Now it turns out that you
can actually go further.

794
00:42:49,630 --> 00:42:52,130
And there's a fairly
sophisticated algorithm

795
00:42:52,130 --> 00:42:54,740
that's sort of beyond
the scope of 6.006

796
00:42:54,740 --> 00:42:56,420
that's an in-place merge sort.

797
00:42:56,420 --> 00:42:59,310


798
00:42:59,310 --> 00:43:03,070
And this in-place
merge sort is kind of

799
00:43:03,070 --> 00:43:08,590
impractical in the sense
that it doesn't do very well

800
00:43:08,590 --> 00:43:10,140
in terms of the
constant factors.

801
00:43:10,140 --> 00:43:15,120
So while it's in-place and
it's still theta n log n.

802
00:43:15,120 --> 00:43:19,720
The problem is that the running
time of an in-place merge sort

803
00:43:19,720 --> 00:43:23,210
is much worse than the
regular merge sort that

804
00:43:23,210 --> 00:43:25,510
uses theta n auxiliary space.

805
00:43:25,510 --> 00:43:28,100
Поэтому люди на самом деле не
испопьзуют сортировку слиянием на месте.

806
00:43:28,100 --> 00:43:29,360
Это очень хорошая статья.

807
00:43:29,360 --> 00:43:31,800
Очень хорошая вещь для прочтения.

808
00:43:31,800 --> 00:43:37,080
Its analysis is a bit
sophisticated for double 0 6.

809
00:43:37,080 --> 00:43:39,030
So we wont go there.

810
00:43:39,030 --> 00:43:40,330
But it does exist.

811
00:43:40,330 --> 00:43:42,003
So you can take merge
sort, and I just

812
00:43:42,003 --> 00:43:45,230
want to let you know that
you can do things in-place.

813
00:43:45,230 --> 00:43:50,560
In terms of numbers, some
experiments we ran a few years

814
00:43:50,560 --> 00:43:54,650
ago-- so these may not
be completely valid

815
00:43:54,650 --> 00:43:56,650
because I'm going to
actually give you numbers--

816
00:43:56,650 --> 00:44:07,380
but merge sort in Python, if
you write a little curve fit

817
00:44:07,380 --> 00:44:17,790
program to do this, is 2.2n log
n microseconds for a given n.

818
00:44:17,790 --> 00:44:19,625
Это что касается
процедуры сортировки слиянием.

819
00:44:19,625 --> 00:44:22,450


820
00:44:22,450 --> 00:44:32,230
And if you look at
insertion sort, in Python,

821
00:44:32,230 --> 00:44:39,410
that's something like 0.2
n square microseconds.

822
00:44:39,410 --> 00:44:42,700
So you see the
constant factors here.

823
00:44:42,700 --> 00:44:48,230
Если вы запустите сортировку вставками на Си,
который является компилируемым языком,

824
00:44:48,230 --> 00:44:50,420
тогда это будет быстрее.

825
00:44:50,420 --> 00:44:52,935
Быстрее где-то в 20 раз.

826
00:44:52,935 --> 00:44:55,440


827
00:44:55,440 --> 00:44:59,230
It's 0.01 n squared
microseconds.

828
00:44:59,230 --> 00:45:00,960
So a little bit of
practice on the side.

829
00:45:00,960 --> 00:45:02,714
We do ask you to write code.

830
00:45:02,714 --> 00:45:03,630
И это важно.

831
00:45:03,630 --> 00:45:04,930
Причина, по которой нам
интересны алгоритмы

832
00:45:04,930 --> 00:45:06,770
в том, что люди
хотят запускать их.

833
00:45:06,770 --> 00:45:13,860
And what you can see is that
you can actually find an n-- so

834
00:45:13,860 --> 00:45:16,300
regardless of whether
you're Python or C,

835
00:45:16,300 --> 00:45:20,020
this tells you that asymptotic
complexity is pretty important

836
00:45:20,020 --> 00:45:24,140
потому что, как
только n превышает 4000,

837
00:45:24,140 --> 00:45:27,260
вы видите, что сортировка
слиянием на Python

838
00:45:27,260 --> 00:45:30,350
побеждает сортировку
вставками на Си.

839
00:45:30,350 --> 00:45:35,430
So the constant
factors get subsumed

840
00:45:35,430 --> 00:45:37,160
beyond certain values of n.

841
00:45:37,160 --> 00:45:39,835
Именно поэтому асимптотическая
сложность важна.

842
00:45:39,835 --> 00:45:41,210
У вас может быть
константа 20 вот здесь,

843
00:45:41,210 --> 00:45:43,270
но это на самом
деле не поможет вам,

844
00:45:43,270 --> 00:45:47,440
так как алгоритм остается
квадратичным.

845
00:45:47,440 --> 00:45:49,400
It stays competitive
for a little bit longer,

846
00:45:49,400 --> 00:45:50,510
but then falls behind.

847
00:45:50,510 --> 00:45:54,520


848
00:45:54,520 --> 00:45:57,387
That's what I wanted
to cover for sorting.

849
00:45:57,387 --> 00:45:58,970
Что ж, надеюсь, у вас
появилось понимание того,

850
00:45:58,970 --> 00:46:02,040
что происходит с этими двумя
алгоритмами сортировки.

851
00:46:02,040 --> 00:46:05,200
В следующий раз мы взглянем на
совершенно другой алгоритм сортировки,

852
00:46:05,200 --> 00:46:08,460
который использует кучи,
другую структуру данных.

853
00:46:08,460 --> 00:46:11,330
Последняя вещь, которую я хочу сделать за
те пару минут, что у меня остались,

854
00:46:11,330 --> 00:46:14,810
is give you a little more
intuition as to recurrence

855
00:46:14,810 --> 00:46:18,680
solving based on this diagram
that I wrote up there.

856
00:46:18,680 --> 00:46:21,460
And so we're going to use
exactly this structure.

857
00:46:21,460 --> 00:46:24,250
And we're going to look at a
couple of different recurrences

858
00:46:24,250 --> 00:46:26,360
that I won't really
motivate in terms

859
00:46:26,360 --> 00:46:29,420
of having a specific
algorithm, but I'll just

860
00:46:29,420 --> 00:46:31,150
write out the recurrence.

861
00:46:31,150 --> 00:46:36,340
And we'll look at the
recursion tree for that.

862
00:46:36,340 --> 00:46:41,900
And I'll try and tease out of
you the complexity associated

863
00:46:41,900 --> 00:46:45,635
with these recurrences of
the overall complexity.

864
00:46:45,635 --> 00:46:49,480


865
00:46:49,480 --> 00:46:58,000
So let's take a look at T
of n equals 2 T of n over 2

866
00:46:58,000 --> 00:47:00,310
plus c n squared.

867
00:47:00,310 --> 00:47:02,820


868
00:47:02,820 --> 00:47:08,360
Let me just call that c--
no need for the brackets.

869
00:47:08,360 --> 00:47:10,970
So constant c times n squared.

870
00:47:10,970 --> 00:47:13,200
So if you had a
crummy merge routine,

871
00:47:13,200 --> 00:47:18,020
and it was taking n square,
and you coded it up wrong.

872
00:47:18,020 --> 00:47:20,050
It's not a great motivation
for this recurrence,

873
00:47:20,050 --> 00:47:23,980
but it's a way this
recurrence could have come up.

874
00:47:23,980 --> 00:47:27,470
So what does this
recursive tree look like?

875
00:47:27,470 --> 00:47:29,580
Well it looks kind of
the same, obviously.

876
00:47:29,580 --> 00:47:33,210
You have c n square; you
have c n square divided by 4;

877
00:47:33,210 --> 00:47:36,620
c n square divided by
4; c n square divided

878
00:47:36,620 --> 00:47:40,620
by 16, four times.

879
00:47:40,620 --> 00:47:44,460
Looking a little bit
different from the other one.

880
00:47:44,460 --> 00:47:47,560
The levels and the leaves
are exactly the same.

881
00:47:47,560 --> 00:47:49,720
Eventually n is going
to go down to 1.

882
00:47:49,720 --> 00:47:53,280
So you will see c
all the way here.

883
00:47:53,280 --> 00:47:54,735
And you're going
to have n leaves.

884
00:47:54,735 --> 00:47:57,880


885
00:47:57,880 --> 00:48:03,380
And you will have, as
before, 1 plus log n levels.

886
00:48:03,380 --> 00:48:05,070
Everything is the same.

887
00:48:05,070 --> 00:48:07,590
And this is why I like this
recursive tree formulation so

888
00:48:07,590 --> 00:48:09,370
much because, now,
all I have to do

889
00:48:09,370 --> 00:48:14,710
is add up the work associated
with each of the levels

890
00:48:14,710 --> 00:48:17,100
to get the solution
to the recurrence.

891
00:48:17,100 --> 00:48:18,770
Now, take a look at
what happens, here.

892
00:48:18,770 --> 00:48:25,350
c n square; c n square divided
by 2; c n square divided by 4.

893
00:48:25,350 --> 00:48:27,890
And this is n times c.

894
00:48:27,890 --> 00:48:30,890


895
00:48:30,890 --> 00:48:34,316
So what does that add up to?

896
00:48:34,316 --> 00:48:35,839
AUDIENCE: [INAUDIBLE]

897
00:48:35,839 --> 00:48:36,880
PROFESSOR: Yeah, exactly.

898
00:48:36,880 --> 00:48:37,920
Exactly right.

899
00:48:37,920 --> 00:48:40,430
So if you look at what
happens, here, this dominates.

900
00:48:40,430 --> 00:48:44,340


901
00:48:44,340 --> 00:48:47,520
All of the other things are
actually less than that.

902
00:48:47,520 --> 00:48:49,250
And you said bounded
by two c n square

903
00:48:49,250 --> 00:48:51,420
because this part is
bounded by c n square

904
00:48:51,420 --> 00:48:54,490
and I already have c n
square up at the top.

905
00:48:54,490 --> 00:48:58,100
So this particular algorithm
that corresponds to this crummy

906
00:48:58,100 --> 00:49:02,300
merge sort, or wherever
this recurrence came from,

907
00:49:02,300 --> 00:49:06,700
is a theta n squared algorithm.

908
00:49:06,700 --> 00:49:10,520
And in this case,
all of the work done

909
00:49:10,520 --> 00:49:15,360
is at the root-- at the
top level of the recursion.

910
00:49:15,360 --> 00:49:17,650
Here, there was a
roughly equal amount

911
00:49:17,650 --> 00:49:21,630
of work done in each of
the different levels.

912
00:49:21,630 --> 00:49:26,610
Here, all of the work
was done at the root.

913
00:49:26,610 --> 00:49:29,460
And so to close
up shop, here, let

914
00:49:29,460 --> 00:49:34,210
me just give you real
quick a recurrence where

915
00:49:34,210 --> 00:49:40,470
all of the work is done at
the leaves, just for closure.

916
00:49:40,470 --> 00:49:45,770
So if I had, magically, a merge
routine that actually happened

917
00:49:45,770 --> 00:49:48,710
in constant time, either
through buggy analysis,

918
00:49:48,710 --> 00:49:51,890
or because of it
was buggy, then what

919
00:49:51,890 --> 00:49:55,650
does the tree look
like for that?

920
00:49:55,650 --> 00:49:58,280
And I can think of
this as being theta 1.

921
00:49:58,280 --> 00:50:01,156
Or I can think of this as
being just a constant c.

922
00:50:01,156 --> 00:50:02,030
I'll stick with that.

923
00:50:02,030 --> 00:50:05,246
So I have c, c, c.

924
00:50:05,246 --> 00:50:09,890


925
00:50:09,890 --> 00:50:11,350
Woah, I tried to move that up.

926
00:50:11,350 --> 00:50:13,750
That doesn't work.

927
00:50:13,750 --> 00:50:15,545
So I have n leaves, as before.

928
00:50:15,545 --> 00:50:18,314


929
00:50:18,314 --> 00:50:19,980
And so if I look at
what I have, here, I

930
00:50:19,980 --> 00:50:21,840
have c at the top level.

931
00:50:21,840 --> 00:50:25,870
I have 2c, and so
on and so forth.

932
00:50:25,870 --> 00:50:26,930
4c.

933
00:50:26,930 --> 00:50:30,940
And then I go all
the way down to nc.

934
00:50:30,940 --> 00:50:33,380
And so what happens
here is this dominates.

935
00:50:33,380 --> 00:50:36,010


936
00:50:36,010 --> 00:50:41,600
And so, in this recurrence, the
whole thing runs in theta n.

937
00:50:41,600 --> 00:50:46,300
So the solution to
that is theta n.

938
00:50:46,300 --> 00:50:50,970
And what you have here
is all of the work

939
00:50:50,970 --> 00:50:54,450
being done at the leaves.

940
00:50:54,450 --> 00:50:58,440
We're not going to really cover
this theorem that gives you

941
00:50:58,440 --> 00:51:02,340
a mechanical way of figuring
this out because we think

942
00:51:02,340 --> 00:51:05,780
the recursive tree is a
better way of looking at.

943
00:51:05,780 --> 00:51:08,920
But you can see that, depending
on what that function is,

944
00:51:08,920 --> 00:51:12,130
in terms of the work being
done in the merge routine,

945
00:51:12,130 --> 00:51:14,490
you'd have different
versions of recurrences.

946
00:51:14,490 --> 00:51:16,990
I'll stick around, and people
who answered questions, please

947
00:51:16,990 --> 00:51:18,270
pick up you cushions.

948
00:51:18,270 --> 00:51:20,240
See you next time.

949
00:51:20,250 --> 00:51:21,740
Внимание! Этот перевод, возможно, ещё не готов.
Его статус: идёт перевод

950
00:51:21,750 --> 00:51:24,240
Переведено на Нотабеноиде
http://translate.kursomir.ru/book/86/516

951
00:51:24,250 --> 00:51:25,240
Переводчики: smiling_giraffe

